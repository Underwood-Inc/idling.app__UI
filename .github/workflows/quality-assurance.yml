name: Quality Assurance

# Concurrency group to cancel in-progress runs on PR updates
concurrency:
  group: tests-pr-${{ github.event.pull_request.number || github.ref }}-${{ github.sha }}
  cancel-in-progress: true

# PERFORMANCE OPTIMIZATION:
# This workflow uses a shared setup job to install dependencies and browsers once,
# then caches them for reuse across all matrix jobs. This significantly reduces
# build time and resource usage compared to each matrix job installing dependencies separately.

on:
  push:
    branches: [main, master]
    paths-ignore:
      - '**.md'
      - 'docs/**'
  pull_request:
    types: [opened, synchronize, reopened]
    paths-ignore:
      - '**.md'
      - 'docs/**'

# Required permissions for GitHub Actions
permissions:
  contents: read
  actions: write
  checks: write
  pull-requests: write

# Environment variables available to all jobs
env:
  AUTH_TRUST_HOST: true
  NEXTAUTH_URL: http://localhost:3000
  # Secrets are encrypted environment variables
  NEXTAUTH_SECRET: ${{ secrets.NEXTAUTH_SECRET }}
  AUTHJS_SESSION_TOKEN: ${{ secrets.AUTHJS_SESSION_TOKEN }}
  AUTHJS_CALLBACK_URL: ${{ secrets.AUTHJS_CALLBACK_URL }}
  AUTHJS_CSRF_TOKEN: ${{ secrets.AUTHJS_CSRF_TOKEN }}
  POSTGRES_HOST: ${{ secrets.POSTGRES_HOST }}
  POSTGRES_PORT: ${{ secrets.POSTGRES_PORT }}
  POSTGRES_USER: ${{ secrets.POSTGRES_USER }}
  POSTGRES_DB: ${{ secrets.POSTGRES_DB }}
  POSTGRES_PASSWORD: ${{ secrets.POSTGRES_PASSWORD }}
  POSTGRES_HOST_AUTH_METHOD: md5
  POSTGRES_INITDB_ARGS: --auth-host=md5
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
  SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}

jobs:
  setup:
    timeout-minutes: 10
    name: Setup Environment
    runs-on: ubuntu-latest
    environment: actions
    outputs:
      cache-key: ${{ steps.cache.outputs.cache-hit }}
      node-version: ${{ steps.node-version.outputs.version }}
    steps:
      # Checkout code with full git history for proper versioning
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      # Setup Node.js using LTS version and output version for reuse
      - uses: actions/setup-node@v4
        id: setup-node
        with:
          node-version: lts/*
          cache: 'yarn' # Enable built-in yarn caching

      # Output Node.js version for other jobs
      - name: Get Node.js version
        id: node-version
        run: echo "version=$(node --version)" >> $GITHUB_OUTPUT

      # Install project dependencies
      - name: Install dependencies
        run: npm install -g yarn && yarn install --check-files

      # Install Playwright browsers for caching
      - name: Install Playwright browsers
        run: npx playwright install --with-deps

      # Cache dependencies and browsers to speed up future runs
      - name: Cache dependencies and browsers
        id: cache
        uses: actions/cache/save@v4
        with:
          path: |
            node_modules
            ~/.cache/playwright
            ~/.cache/ms-playwright
          key: ${{ runner.os }}-deps-browsers-${{ hashFiles('**/yarn.lock', '**/package.json') }}

  playwright-tests:
    name: Playwright Tests
    needs: setup
    runs-on: ubuntu-latest
    timeout-minutes: 30
    environment: actions
    continue-on-error: true # Make Playwright tests optional - don't fail the workflow
    strategy:
      fail-fast: false # Continue with other shards if one fails
      matrix:
        shard: [1, 2, 3] # Run tests in 3 parallel shards
    services:
      # PostgreSQL service container for E2E tests
      postgres:
        image: postgres
        env:
          # Database configuration
          POSTGRES_HOST: ${{ secrets.POSTGRES_HOST }}
          POSTGRES_PORT: ${{ secrets.POSTGRES_PORT }}
          POSTGRES_USER: ${{ secrets.POSTGRES_USER }}
          POSTGRES_DB: ${{ secrets.POSTGRES_DB }}
          POSTGRES_PASSWORD: ${{ secrets.POSTGRES_PASSWORD }}
          POSTGRES_HOST_AUTH_METHOD: md5
          POSTGRES_INITDB_ARGS: --auth-host=md5
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    steps:
      - uses: actions/checkout@v4

      # Use the same Node.js version as setup job
      - uses: actions/setup-node@v4
        with:
          node-version: lts/*
          cache: 'yarn'

      # Restore cached dependencies and browsers from setup job
      - name: Restore dependencies and browsers cache
        id: cache-restore
        uses: actions/cache/restore@v4
        with:
          path: |
            node_modules
            ~/.cache/playwright
            ~/.cache/ms-playwright
          key: ${{ runner.os }}-deps-browsers-${{ hashFiles('**/yarn.lock', '**/package.json') }}
          restore-keys: |
            ${{ runner.os }}-deps-browsers-
            ${{ runner.os }}-deps-
          fail-on-cache-miss: false

      # Install dependencies if cache miss (first run or cache eviction)
      - name: Install dependencies and browsers
        if: steps.cache-restore.outputs.cache-hit != 'true'
        run: |
          yarn install --check-files
          npx playwright install --with-deps

      # Setup test database
      - name: Run migrations
        run: psql -v POSTGRES_DB="$POSTGRES_DB" -v POSTGRES_PASSWORD="$POSTGRES_PASSWORD" -v POSTGRES_USER="$POSTGRES_USER" -f ./src/lib/scripts/000-init.sql postgresql://${{secrets.POSTGRES_USER}}:${{secrets.POSTGRES_PASSWORD}}@${{secrets.POSTGRES_HOST}}:${{secrets.POSTGRES_PORT}}

      # Run E2E tests with sharding
      - name: Run Playwright tests (Shard ${{ matrix.shard }}/3)
        run: |
          echo "::group::Running Playwright Tests (Shard ${{ matrix.shard }}/3)"
          # Create directories for each project
          mkdir -p test-results/{chromium,firefox,webkit} playwright-report

          # Run tests with reporters configured in playwright.config.ts
          IS_CI=1 FORCE_COLOR=1 yarn playwright test \
            --shard=${{ matrix.shard }}/3

          # Debug: Show test results
          echo "Test results directory contents:"
          ls -la test-results/
          echo "\nTest results by project:"
          for dir in test-results/*/; do
            echo "\n$dir:"
            ls -la "$dir"
          done
          echo "::endgroup::"

      # Upload test results for this shard
      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: playwright-results-${{ matrix.shard }}
          path: |
            test-results/**/*
            playwright-report/**/*
          retention-days: 30

      # Upload traces only on failure
      - name: Upload test traces on failure
        if: ${{ failure() && !cancelled() }}
        uses: actions/upload-artifact@v4
        with:
          name: playwright-traces-${{ matrix.shard }}
          path: test-results/
          retention-days: 7

  jest-tests:
    timeout-minutes: 15
    name: Jest Tests
    needs: setup
    runs-on: ubuntu-latest
    environment: actions
    strategy:
      fail-fast: false
      matrix:
        shard: [1, 2, 3] # Run tests in 3 parallel shards
    steps:
      - uses: actions/checkout@v4

      # Use the same Node.js version as setup job
      - uses: actions/setup-node@v4
        with:
          node-version: lts/*
          cache: 'yarn'

      # Restore cached dependencies from setup job
      - name: Restore dependencies cache
        id: cache-restore
        uses: actions/cache/restore@v4
        with:
          path: |
            node_modules
            ~/.cache/playwright
            ~/.cache/ms-playwright
          key: ${{ runner.os }}-deps-browsers-${{ hashFiles('**/yarn.lock', '**/package.json') }}
          restore-keys: |
            ${{ runner.os }}-deps-browsers-
            ${{ runner.os }}-deps-
          fail-on-cache-miss: false

      # Install dependencies if cache miss (first run or cache eviction)
      - name: Install dependencies
        if: steps.cache-restore.outputs.cache-hit != 'true'
        run: yarn install --check-files

      # Run unit tests with sharding
      - name: Run Jest tests (Shard ${{ matrix.shard }}/3)
        run: |
          echo "::group::Running Jest Tests (Shard ${{ matrix.shard }}/3)"
          FORCE_COLOR=1 yarn test:coverage --ci --colors --json --shard=${{ matrix.shard }}/3 --testLocationInResults --outputFile="$GITHUB_WORKSPACE/jest-results-${{ matrix.shard }}.json"
          echo "::endgroup::"

      # Upload coverage reports for each shard
      - name: Upload Jest coverage
        if: ${{ !cancelled() }}
        uses: actions/upload-artifact@v4
        with:
          name: jest-coverage-${{ matrix.shard }}
          path: coverage/
          retention-days: 30

  # Documentation coverage job integrated into test suite
  documentation-coverage:
    timeout-minutes: 10
    name: Documentation Coverage
    needs: setup
    runs-on: ubuntu-latest
    environment: actions
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      # Use the same Node.js version as setup job
      - uses: actions/setup-node@v4
        with:
          node-version: lts/*
          cache: 'yarn'

      # Restore cached dependencies from setup job
      - name: Restore dependencies cache
        id: cache-restore
        uses: actions/cache/restore@v4
        with:
          path: |
            node_modules
            ~/.cache/playwright
            ~/.cache/ms-playwright
          key: ${{ runner.os }}-deps-browsers-${{ hashFiles('**/yarn.lock', '**/package.json') }}
          restore-keys: |
            ${{ runner.os }}-deps-browsers-
            ${{ runner.os }}-deps-
          fail-on-cache-miss: false

      # Install dependencies if cache miss
      - name: Install dependencies
        if: steps.cache-restore.outputs.cache-hit != 'true'
        run: yarn install --check-files

      - name: üêç Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: üì¶ Install Python dependencies
        run: |
          pip install interrogate pydocstyle

      - name: üêç Check Python docstring coverage
        id: interrogate
        run: |
          # Run interrogate and capture output
          if interrogate --fail-under=85 --verbose=2 src/ > interrogate_output.txt 2>&1; then
            echo "interrogate_passed=true" >> $GITHUB_OUTPUT
          else
            echo "interrogate_passed=false" >> $GITHUB_OUTPUT
          fi

          # Extract docstring coverage percentage
          DOCSTRING_COVERAGE=$(grep -oP 'TOTAL.*?(\K\d+(?=\.\d+%))' interrogate_output.txt || echo "0")
          echo "docstring_coverage=${DOCSTRING_COVERAGE}" >> $GITHUB_OUTPUT
        continue-on-error: true

      - name: üìö Check documentation files coverage
        id: docs-coverage
        run: |
          # üî• COMPREHENSIVE DOCUMENTATION COVERAGE INVESTIGATION üî•
          total_files=0
          documented_files=0
          missing_files=()
          pr_files=()
          pr_missing_files=()

          # Get list of changed files in this PR (if applicable)
          if [ "${{ github.event_name }}" == "pull_request" ]; then
            git fetch origin ${{ github.base_ref }}
            changed_files=$(git diff --name-only origin/${{ github.base_ref }}...HEAD | grep -E '\.(ts|tsx|js|jsx)$' | grep '^src/' || true)
          else
            changed_files=""
          fi

          # üìä FULL CODEBASE DOCUMENTATION AUDIT üìä
          echo "## üö® BREAKING: Documentation Coverage Scandal Exposed! üö®" > coverage_report.md
          echo "" >> coverage_report.md
          echo "### üì∞ **EXCLUSIVE INVESTIGATION REVEALS SHOCKING TRUTH ABOUT CODE DOCUMENTATION!** üì∞" >> coverage_report.md
          echo "" >> coverage_report.md

          # Check ALL TypeScript/JavaScript files in src/
          for file in $(find src/ -name "*.ts" -o -name "*.tsx" -o -name "*.js" -o -name "*.jsx" 2>/dev/null || true); do
            if [ -f "$file" ]; then
              total_files=$((total_files + 1))
              
              # Convert src/path/file.ts to DOCS/src/path/file.md (properly handle extensions)
              doc_file="DOCS/${file%.*}.md"
              
              if [ -f "$doc_file" ]; then
                documented_files=$((documented_files + 1))
              else
                missing_files+=("$file")
              fi
              
              # Check if this file is in the PR
              if [ -n "$changed_files" ] && echo "$changed_files" | grep -q "^$file$"; then
                pr_files+=("$file")
                if [ ! -f "$doc_file" ]; then
                  pr_missing_files+=("$file")
                fi
              fi
            fi
          done

          # Calculate coverage
          if [ $total_files -eq 0 ]; then
            DOC_COVERAGE=100
          else
            DOC_COVERAGE=$((documented_files * 100 / total_files))
          fi

          echo "doc_coverage=${DOC_COVERAGE}" >> $GITHUB_OUTPUT
          echo "total_files=${total_files}" >> $GITHUB_OUTPUT
          echo "documented_files=${documented_files}" >> $GITHUB_OUTPUT
          echo "pr_files_count=${#pr_files[@]}" >> $GITHUB_OUTPUT
          echo "pr_missing_count=${#pr_missing_files[@]}" >> $GITHUB_OUTPUT

          if [ $DOC_COVERAGE -ge 85 ]; then
            echo "docs_coverage_passed=true" >> $GITHUB_OUTPUT
          else
            echo "docs_coverage_passed=false" >> $GITHUB_OUTPUT
          fi

          # üé≠ DRAMATIC TABLOID REPORTING üé≠
          echo "### üìà **SHOCKING STATISTICS REVEALED!** üìà" >> coverage_report.md
          echo "" >> coverage_report.md
          echo "| üèÜ **METRIC** | üî¢ **COUNT** | üìä **PERCENTAGE** |" >> coverage_report.md
          echo "|---------------|---------------|-------------------|" >> coverage_report.md
          echo "| **Total Source Files** | **${total_files}** | **100%** |" >> coverage_report.md
          echo "| **Documented Files** | **${documented_files}** | **${DOC_COVERAGE}%** |" >> coverage_report.md
          echo "| **Missing Documentation** | **${#missing_files[@]}** | **$((100 - DOC_COVERAGE))%** |" >> coverage_report.md
          echo "" >> coverage_report.md

          # Generate DRAMATIC missing files report
          if [ ${#missing_files[@]} -gt 0 ]; then
            echo "### üö® **SCANDAL: ${#missing_files[@]} Files Found WITHOUT Documentation!** üö®" >> coverage_report.md
            echo "" >> coverage_report.md
            echo "*Our investigative team has uncovered a shocking conspiracy of undocumented code!*" >> coverage_report.md
            echo "" >> coverage_report.md
            echo "| üîç **UNDOCUMENTED SOURCE FILE** | üìù **REQUIRED DOCUMENTATION** | üö® **STATUS** |" >> coverage_report.md
            echo "|----------------------------------|--------------------------------|---------------|" >> coverage_report.md
            printf '%s\n' "${missing_files[@]}" | while read -r line; do
              src_file="$line"
              doc_file="DOCS/${src_file%.*}.md"
              echo "| \`${src_file}\` | \`${doc_file}\` | ‚ùå **MISSING** |" >> coverage_report.md
            done
            echo "" >> coverage_report.md
            echo "üí• **BREAKING NEWS:** These files are operating WITHOUT proper documentation coverage!" >> coverage_report.md
          else
            echo "### üéâ **MIRACLE: ALL FILES HAVE DOCUMENTATION!** üéâ" >> coverage_report.md
            echo "" >> coverage_report.md
            echo "‚ú® *In a stunning turn of events, our investigation reveals PERFECT documentation coverage!* ‚ú®" >> coverage_report.md
          fi
          echo "" >> coverage_report.md

          # Generate PR-specific TABLOID report
          if [ "${{ github.event_name }}" == "pull_request" ]; then
            echo "### üî• **THIS JUST IN: PR Documentation Status EXPOSED!** üî•" > pr_coverage_report.md
            echo "" >> pr_coverage_report.md
            echo "**üéØ Files Changed in This PR:** ${#pr_files[@]}" >> pr_coverage_report.md
            echo "**üìù Missing Documentation:** ${#pr_missing_files[@]}" >> pr_coverage_report.md
            echo "" >> pr_coverage_report.md

            if [ ${#pr_missing_files[@]} -gt 0 ]; then
              echo "### üí£ **BOMBSHELL: PR Contains Undocumented Files!** üí£" >> pr_coverage_report.md
              echo "" >> pr_coverage_report.md
              echo "*EXCLUSIVE: Our sources reveal that this PR introduces changes to files lacking proper documentation!*" >> pr_coverage_report.md
              echo "" >> pr_coverage_report.md
              echo "| üö® **UNDOCUMENTED FILE IN PR** | üìö **REQUIRED DOCUMENTATION** | üéØ **ACTION NEEDED** |" >> pr_coverage_report.md
              echo "|--------------------------------|--------------------------------|----------------------|" >> pr_coverage_report.md
              printf '%s\n' "${pr_missing_files[@]}" | while read -r line; do
                src_file="$line"
                doc_file="DOCS/${src_file%.*}.md"
                echo "| \`${src_file}\` | \`${doc_file}\` | üìù **CREATE DOCS** |" >> pr_coverage_report.md
              done
              echo "" >> pr_coverage_report.md
              echo "üî• **URGENT:** Create these documentation files to maintain code quality standards!" >> pr_coverage_report.md
            else
              if [ ${#pr_files[@]} -gt 0 ]; then
                echo "### üèÜ **VICTORY: All PR Files Have Documentation!** üèÜ" >> pr_coverage_report.md
                echo "" >> pr_coverage_report.md
                echo "‚ú® *CELEBRATION TIME: Every single file in this PR has proper documentation coverage!* ‚ú®" >> pr_coverage_report.md
                echo "" >> pr_coverage_report.md
                echo "| üìÅ **DOCUMENTED FILE IN PR** | üìö **DOCUMENTATION EXISTS** | ‚úÖ **STATUS** |" >> pr_coverage_report.md
                echo "|-------------------------------|------------------------------|---------------|" >> pr_coverage_report.md
                printf '%s\n' "${pr_files[@]}" | while read -r line; do
                  src_file="$line"
                  doc_file="DOCS/${src_file%.*}.md"
                  echo "| \`${src_file}\` | \`${doc_file}\` | üéâ **PERFECT** |" >> pr_coverage_report.md
                done
              else
                echo "### üì∞ **REPORT: No Source Files Changed in This PR** üì∞" >> pr_coverage_report.md
                echo "" >> pr_coverage_report.md
                echo "‚ÑπÔ∏è *Our investigation shows this PR doesn't modify any source files requiring documentation.*" >> pr_coverage_report.md
              fi
            fi
          fi
        continue-on-error: true

      - name: üé® Generate SonarCloud compatible metrics
        id: generate-metrics
        run: |
          # Calculate overall documentation coverage (weighted average)
          DOC_COVERAGE="${{ steps.docs-coverage.outputs.doc_coverage }}"
          DOCSTRING_COVERAGE="${{ steps.interrogate.outputs.docstring_coverage }}"
          OVERALL_COVERAGE=$(python -c "print(int(($DOC_COVERAGE * 0.6) + ($DOCSTRING_COVERAGE * 0.4)))")

          echo "overall_coverage=${OVERALL_COVERAGE}" >> $GITHUB_OUTPUT

          # Create SonarCloud-compatible generic test execution report
          mkdir -p coverage
          cat > coverage/documentation-test-execution.xml << EOF
          <?xml version="1.0" encoding="UTF-8"?>
          <testExecutions version="1">
            <file path="tests/documentation-coverage-tests.js">
              <testCase name="Documentation Files Coverage Test (${DOC_COVERAGE}%)" duration="100">
                $([ $DOC_COVERAGE -ge 85 ] && echo "" || echo '<failure message="Documentation files coverage below 85%">Only '${DOC_COVERAGE}'% of source files have documentation. Expected: >= 85%</failure>')
              </testCase>
              <testCase name="Python Docstring Coverage Test (${DOCSTRING_COVERAGE}%)" duration="50">
                $([ $DOCSTRING_COVERAGE -ge 85 ] && echo "" || echo '<failure message="Python docstring coverage below 85%">Only '${DOCSTRING_COVERAGE}'% of Python functions have docstrings. Expected: >= 85%</failure>')
              </testCase>
              <testCase name="Overall Documentation Coverage Test (${OVERALL_COVERAGE}%)" duration="75">
                $([ $OVERALL_COVERAGE -ge 85 ] && echo "" || echo '<failure message="Overall documentation coverage below 85%">Overall documentation coverage is '${OVERALL_COVERAGE}'%. Expected: >= 85%</failure>')
              </testCase>
            </file>
          </testExecutions>
          EOF

          # Also create a generic coverage report for SonarCloud metrics
          cat > coverage/documentation-generic-coverage.xml << EOF
          <?xml version="1.0" encoding="UTF-8"?>
          <coverage version="1">
            <file path="metrics/documentation-coverage.md">
              <lineToCover lineNumber="1" covered="$([ $DOC_COVERAGE -ge 85 ] && echo "true" || echo "false")"/>
              <lineToCover lineNumber="2" covered="$([ $DOCSTRING_COVERAGE -ge 85 ] && echo "true" || echo "false")"/>
              <lineToCover lineNumber="3" covered="$([ $OVERALL_COVERAGE -ge 85 ] && echo "true" || echo "false")"/>
            </file>
          </coverage>
          EOF

      # Upload documentation coverage artifacts for SonarCloud
      - name: üì§ Upload documentation coverage artifacts
        uses: actions/upload-artifact@v4
        with:
          name: documentation-coverage-reports
          path: |
            coverage/documentation-test-execution.xml
            coverage/documentation-generic-coverage.xml
          retention-days: 7

      - name: üí¨ Comment on PR with detailed TABLOID results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');

            const interrogatePassed = '${{ steps.interrogate.outputs.interrogate_passed }}' === 'true';
            const docsCoveragePassed = '${{ steps.docs-coverage.outputs.docs_coverage_passed }}' === 'true';
            const overallCoverage = '${{ steps.generate-metrics.outputs.overall_coverage }}';
            const docCoverage = '${{ steps.docs-coverage.outputs.doc_coverage }}';
            const docstringCoverage = '${{ steps.interrogate.outputs.docstring_coverage }}';

            const overallStatus = interrogatePassed && docsCoveragePassed ? '‚úÖ' : '‚ùå';

            let comment = `## ${overallStatus} üö® BREAKING: Documentation Coverage Investigation Results! üö®\n\n`;
            comment += `### üìä **EXCLUSIVE COVERAGE STATISTICS**\n\n`;
            comment += `| üèÜ **CHECK** | üéØ **STATUS** | üìà **COVERAGE** |\n`;
            comment += `|--------------|---------------|------------------|\n`;
            comment += `| Python Docstrings | ${interrogatePassed ? '‚úÖ **PASSED**' : '‚ùå **FAILED**'} | **${docstringCoverage}%** |\n`;
            comment += `| Documentation Files | ${docsCoveragePassed ? '‚úÖ **PASSED**' : '‚ùå **FAILED**'} | **${docCoverage}%** |\n`;
            comment += `| **üéØ OVERALL COVERAGE** | ${overallStatus} **${overallStatus === '‚úÖ' ? 'PASSED' : 'FAILED'}** | **${overallCoverage}%** |\n\n`;

            // Add PR-specific documentation status
            try {
              if (fs.existsSync('pr_coverage_report.md')) {
                const prReportContent = fs.readFileSync('pr_coverage_report.md', 'utf8');
                comment += `<details>\n<summary>üîç **EXCLUSIVE: This PR's Documentation Status EXPOSED!**</summary>\n\n`;
                comment += prReportContent + '\n';
                comment += `</details>\n\n`;
              }
            } catch (error) {
              console.log('Error reading PR coverage report:', error);
            }

            // Add detailed reports in collapsible sections if there are issues
            if (!interrogatePassed) {
              comment += `<details>\n<summary>üêç **SCANDAL: Python Docstring Coverage Details REVEALED!**</summary>\n\n`;
              
              try {
                if (fs.existsSync('interrogate_output.txt')) {
                  const interrogateOutput = fs.readFileSync('interrogate_output.txt', 'utf8');
                  comment += '```\n' + interrogateOutput + '\n```\n';
                } else {
                  comment += '‚ùå **SHOCKING:** No detailed interrogate output available!\n';
                }
              } catch (error) {
                comment += 'üí• **ERROR:** Failed to read interrogate output!\n';
              }
              
              comment += `\n</details>\n\n`;
            }

            // Add full codebase documentation status
            if (!docsCoveragePassed) {
              comment += `<details>\n<summary>üìö **BOMBSHELL: Full Codebase Documentation Coverage EXPOSED!**</summary>\n\n`;
              
              try {
                if (fs.existsSync('coverage_report.md')) {
                  const fullReportContent = fs.readFileSync('coverage_report.md', 'utf8');
                  comment += fullReportContent + '\n';
                } else {
                  comment += `**üö® BREAKING:** ${{ steps.docs-coverage.outputs.documented_files }} of ${{ steps.docs-coverage.outputs.total_files }} files documented\n\n`;
                  comment += `üí• **SCANDAL:** Some source files are missing corresponding documentation files! `;
                  comment += `Our investigative team demands you create documentation files in the \`DOCS/\` directory!\n\n`;
                  comment += `**üì∞ EXPECTED DOCUMENTATION STRUCTURE:**\n`;
                  comment += `- For \`src/components/Button.tsx\` ‚Üí create \`DOCS/src/components/Button.md\`\n`;
                  comment += `- For \`src/utils/helpers.ts\` ‚Üí create \`DOCS/src/utils/helpers.md\`\n`;
                }
              } catch (error) {
                comment += 'üí• **ERROR:** Failed to read full coverage report!\n';
              }
              
              comment += `</details>\n\n`;
            }

            comment += `### üéØ **SonarCloud Integration**\n`;
            comment += `üìä *Coverage data will be available in SonarCloud dashboard with custom metrics*\n\n`;
            comment += `---\n*üé≠ This dramatic expos√© was automatically generated by the Quality Assurance workflow's investigative journalism team.*`;

            // Find existing documentation coverage comment and update/create
            const { data: comments } = await github.rest.issues.listComments({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo
            });

            const existingComment = comments.find(comment => 
              comment.body.includes('Documentation Coverage Investigation Results') ||
              comment.body.includes('Documentation Coverage Report')
            );

            if (existingComment) {
              console.log('üîÑ Updating existing documentation coverage comment...');
              await github.rest.issues.updateComment({
                comment_id: existingComment.id,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: comment
              });
            } else {
              console.log('üìù Creating new documentation coverage comment...');
              await github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: comment
              });
            }

            console.log('‚úÖ Documentation coverage comment posted successfully!');

      - name: Upload documentation coverage artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: documentation-coverage
          path: |
            coverage/documentation-coverage.xml
            coverage/sonar-documentation.properties
            interrogate_output.txt
          retention-days: 30

  # SonarCloud analysis job (matches original working setup)
  sonar:
    timeout-minutes: 15
    name: SonarCloud Analysis
    needs: [playwright-tests, jest-tests, documentation-coverage]
    if: ${{ !cancelled() }} # Run even if some tests fail
    runs-on: ubuntu-latest
    environment: actions
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      # Download all workflow artifacts including documentation coverage
      - name: Download all workflow run artifacts
        continue-on-error: true
        uses: actions/download-artifact@v4

      # Run SonarCloud analysis (exactly like the original working setup)
      - name: SonarCloud Scan
        continue-on-error: true
        uses: SonarSource/sonarqube-scan-action@v5.0.0
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}

  # Status reporting jobs that consolidate matrix results
  playwright-status:
    name: Playwright Status
    needs: playwright-tests
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Report Playwright Status
        uses: actions/github-script@v7
        with:
          script: |
            const jobs = ${{ toJson(needs.playwright-tests.result) }};
            const success = jobs === 'success';
            const skipped = jobs === 'skipped';

            console.log(`Playwright tests result: ${jobs}`);

            if (skipped) {
              console.log('‚úÖ Playwright tests were skipped');
            } else if (success) {
              console.log('‚úÖ All Playwright tests passed');
            } else {
              console.log('‚ùå Some Playwright tests failed (non-blocking)');
            }

  jest-status:
    name: Jest Status
    needs: jest-tests
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Report Jest Status
        uses: actions/github-script@v7
        with:
          script: |
            const jobs = ${{ toJson(needs.jest-tests.result) }};
            const success = jobs === 'success';

            console.log(`Jest tests result: ${jobs}`);

            if (success) {
              console.log('‚úÖ All Jest tests passed');
            } else {
              console.log('‚ùå Jest tests failed');
              process.exit(1);
            }

  # Final status job
  tests-complete:
    name: Quality Assurance Complete
    needs: [jest-status, playwright-status, documentation-coverage, sonar]
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Report Final Status
        run: |
          echo "üß™ Quality Assurance Complete"
          echo "============================"
          echo "Jest: ${{ needs.jest-status.result }}"
          echo "Playwright: ${{ needs.playwright-status.result }}"
          echo "Documentation: ${{ needs.documentation-coverage.result }}"
          echo "SonarCloud: ${{ needs.sonar.result }}"

          if [[ "${{ needs.jest-status.result }}" == "success" ]]; then
            echo "‚úÖ All required tests passed"
            if [[ "${{ needs.documentation-coverage.result }}" == "success" ]]; then
              echo "‚úÖ Documentation coverage meets requirements"
            else
              echo "‚ö†Ô∏è Documentation coverage needs attention (non-blocking)"
            fi
            if [[ "${{ needs.sonar.result }}" == "success" ]]; then
              echo "‚úÖ SonarCloud analysis completed successfully"
            else
              echo "‚ö†Ô∏è SonarCloud analysis had issues (non-blocking)"
            fi
          else
            echo "‚ùå Required tests failed"
            exit 1
          fi
