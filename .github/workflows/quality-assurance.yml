name: Quality Assurance

# Concurrency group to cancel in-progress runs on PR updates
concurrency:
  group: tests-pr-${{ github.event.pull_request.number || github.ref }}-${{ github.sha }}
  cancel-in-progress: true

# PERFORMANCE OPTIMIZATION:
# This workflow uses a shared setup job to install dependencies and browsers once,
# then caches them for reuse across all matrix jobs. This significantly reduces
# build time and resource usage compared to each matrix job installing dependencies separately.

on:
  push:
    branches: [main, master]
    paths-ignore:
      - '**.md'
      - 'docs/**'
  pull_request:
    types: [opened, synchronize, reopened]
    paths-ignore:
      - '**.md'
      - 'docs/**'

# Required permissions for GitHub Actions
permissions:
  contents: read
  actions: write
  checks: write
  pull-requests: write

# Environment variables available to all jobs
env:
  AUTH_TRUST_HOST: true
  NEXTAUTH_URL: http://localhost:3000
  # Secrets are encrypted environment variables
  NEXTAUTH_SECRET: ${{ secrets.NEXTAUTH_SECRET }}
  AUTHJS_SESSION_TOKEN: ${{ secrets.AUTHJS_SESSION_TOKEN }}
  AUTHJS_CALLBACK_URL: ${{ secrets.AUTHJS_CALLBACK_URL }}
  AUTHJS_CSRF_TOKEN: ${{ secrets.AUTHJS_CSRF_TOKEN }}
  POSTGRES_HOST: ${{ secrets.POSTGRES_HOST }}
  POSTGRES_PORT: ${{ secrets.POSTGRES_PORT }}
  POSTGRES_USER: ${{ secrets.POSTGRES_USER }}
  POSTGRES_DB: ${{ secrets.POSTGRES_DB }}
  POSTGRES_PASSWORD: ${{ secrets.POSTGRES_PASSWORD }}
  POSTGRES_HOST_AUTH_METHOD: md5
  POSTGRES_INITDB_ARGS: --auth-host=md5
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
  SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}

jobs:
  setup:
    timeout-minutes: 10
    name: Setup Environment
    runs-on: ubuntu-latest
    environment: actions
    outputs:
      cache-key: ${{ steps.cache.outputs.cache-hit }}
      node-version: ${{ steps.node-version.outputs.version }}
    steps:
      # Checkout code with full git history for proper versioning
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      # Setup Node.js using LTS version and output version for reuse
      - uses: actions/setup-node@v4
        id: setup-node
        with:
          node-version: lts/*
          cache: 'yarn' # Enable built-in yarn caching

      # Output Node.js version for other jobs
      - name: Get Node.js version
        id: node-version
        run: echo "version=$(node --version)" >> $GITHUB_OUTPUT

      # Install project dependencies
      - name: Install dependencies
        run: npm install -g yarn && yarn install --check-files

      # Install Playwright browsers for caching
      - name: Install Playwright browsers
        run: npx playwright install --with-deps

      # Cache dependencies and browsers to speed up future runs
      - name: Cache dependencies and browsers
        id: cache
        uses: actions/cache/save@v4
        with:
          path: |
            node_modules
            ~/.cache/playwright
            ~/.cache/ms-playwright
          key: ${{ runner.os }}-deps-browsers-${{ hashFiles('**/yarn.lock', '**/package.json') }}

  playwright-tests:
    name: Playwright Tests
    needs: setup
    runs-on: ubuntu-latest
    timeout-minutes: 30
    environment: actions
    continue-on-error: true # Make Playwright tests optional - don't fail the workflow
    strategy:
      fail-fast: false # Continue with other shards if one fails
      matrix:
        shard: [1, 2, 3] # Run tests in 3 parallel shards
    services:
      # PostgreSQL service container for E2E tests
      postgres:
        image: postgres
        env:
          # Database configuration
          POSTGRES_HOST: ${{ secrets.POSTGRES_HOST }}
          POSTGRES_PORT: ${{ secrets.POSTGRES_PORT }}
          POSTGRES_USER: ${{ secrets.POSTGRES_USER }}
          POSTGRES_DB: ${{ secrets.POSTGRES_DB }}
          POSTGRES_PASSWORD: ${{ secrets.POSTGRES_PASSWORD }}
          POSTGRES_HOST_AUTH_METHOD: md5
          POSTGRES_INITDB_ARGS: --auth-host=md5
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    steps:
      - uses: actions/checkout@v4

      # Use the same Node.js version as setup job
      - uses: actions/setup-node@v4
        with:
          node-version: lts/*
          cache: 'yarn'

      # Restore cached dependencies and browsers from setup job
      - name: Restore dependencies and browsers cache
        id: cache-restore
        uses: actions/cache/restore@v4
        with:
          path: |
            node_modules
            ~/.cache/playwright
            ~/.cache/ms-playwright
          key: ${{ runner.os }}-deps-browsers-${{ hashFiles('**/yarn.lock', '**/package.json') }}
          restore-keys: |
            ${{ runner.os }}-deps-browsers-
            ${{ runner.os }}-deps-
          fail-on-cache-miss: false

      # Install dependencies if cache miss (first run or cache eviction)
      - name: Install dependencies and browsers
        if: steps.cache-restore.outputs.cache-hit != 'true'
        run: |
          yarn install --check-files
          npx playwright install --with-deps

      # Setup test database
      - name: Run migrations
        run: psql -v POSTGRES_DB="$POSTGRES_DB" -v POSTGRES_PASSWORD="$POSTGRES_PASSWORD" -v POSTGRES_USER="$POSTGRES_USER" -f ./src/lib/scripts/000-init.sql postgresql://${{secrets.POSTGRES_USER}}:${{secrets.POSTGRES_PASSWORD}}@${{secrets.POSTGRES_HOST}}:${{secrets.POSTGRES_PORT}}

      # Run E2E tests with sharding
      - name: Run Playwright tests (Shard ${{ matrix.shard }}/3)
        run: |
          echo "::group::Running Playwright Tests (Shard ${{ matrix.shard }}/3)"
          # Create directories for each project
          mkdir -p test-results/{chromium,firefox,webkit} playwright-report

          # Run tests with reporters configured in playwright.config.ts
          IS_CI=1 FORCE_COLOR=1 yarn playwright test \
            --shard=${{ matrix.shard }}/3

          # Debug: Show test results
          echo "Test results directory contents:"
          ls -la test-results/
          echo "\nTest results by project:"
          for dir in test-results/*/; do
            echo "\n$dir:"
            ls -la "$dir"
          done
          echo "::endgroup::"

      # Upload test results for this shard
      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: playwright-results-${{ matrix.shard }}
          path: |
            test-results/**/*
            playwright-report/**/*
          retention-days: 30

      # Upload traces only on failure
      - name: Upload test traces on failure
        if: ${{ failure() && !cancelled() }}
        uses: actions/upload-artifact@v4
        with:
          name: playwright-traces-${{ matrix.shard }}
          path: test-results/
          retention-days: 7

  jest-tests:
    timeout-minutes: 15
    name: Jest Tests
    needs: setup
    runs-on: ubuntu-latest
    environment: actions
    strategy:
      fail-fast: false
      matrix:
        shard: [1, 2, 3] # Run tests in 3 parallel shards
    steps:
      - uses: actions/checkout@v4

      # Use the same Node.js version as setup job
      - uses: actions/setup-node@v4
        with:
          node-version: lts/*
          cache: 'yarn'

      # Restore cached dependencies from setup job
      - name: Restore dependencies cache
        id: cache-restore
        uses: actions/cache/restore@v4
        with:
          path: |
            node_modules
            ~/.cache/playwright
            ~/.cache/ms-playwright
          key: ${{ runner.os }}-deps-browsers-${{ hashFiles('**/yarn.lock', '**/package.json') }}
          restore-keys: |
            ${{ runner.os }}-deps-browsers-
            ${{ runner.os }}-deps-
          fail-on-cache-miss: false

      # Install dependencies if cache miss (first run or cache eviction)
      - name: Install dependencies
        if: steps.cache-restore.outputs.cache-hit != 'true'
        run: yarn install --check-files

      # Run unit tests with sharding
      - name: Run Jest tests (Shard ${{ matrix.shard }}/3)
        run: |
          echo "::group::Running Jest Tests (Shard ${{ matrix.shard }}/3)"
          FORCE_COLOR=1 yarn test:coverage --ci --colors --json --shard=${{ matrix.shard }}/3 --testLocationInResults --outputFile="$GITHUB_WORKSPACE/jest-results-${{ matrix.shard }}.json"
          echo "::endgroup::"

      # Upload coverage reports for each shard
      - name: Upload Jest coverage
        if: ${{ !cancelled() }}
        uses: actions/upload-artifact@v4
        with:
          name: jest-coverage-${{ matrix.shard }}
          path: coverage/
          retention-days: 30

  # Documentation coverage job integrated into test suite
  documentation-coverage:
    timeout-minutes: 10
    name: Documentation Coverage
    needs: setup
    runs-on: ubuntu-latest
    environment: actions
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      # Use the same Node.js version as setup job
      - uses: actions/setup-node@v4
        with:
          node-version: lts/*
          cache: 'yarn'

      # Restore cached dependencies from setup job
      - name: Restore dependencies cache
        id: cache-restore
        uses: actions/cache/restore@v4
        with:
          path: |
            node_modules
            ~/.cache/playwright
            ~/.cache/ms-playwright
          key: ${{ runner.os }}-deps-browsers-${{ hashFiles('**/yarn.lock', '**/package.json') }}
          restore-keys: |
            ${{ runner.os }}-deps-browsers-
            ${{ runner.os }}-deps-
          fail-on-cache-miss: false

      # Install dependencies if cache miss
      - name: Install dependencies
        if: steps.cache-restore.outputs.cache-hit != 'true'
        run: yarn install --check-files

      - name: üêç Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: üì¶ Install Python dependencies
        run: |
          pip install interrogate pydocstyle

      - name: üêç Check Python docstring coverage
        id: interrogate
        run: |
          # Run interrogate and capture output
          if interrogate --fail-under=85 --verbose=2 src/ > interrogate_output.txt 2>&1; then
            echo "interrogate_passed=true" >> $GITHUB_OUTPUT
          else
            echo "interrogate_passed=false" >> $GITHUB_OUTPUT
          fi

          # Extract docstring coverage percentage
          DOCSTRING_COVERAGE=$(grep -oP 'TOTAL.*?(\K\d+(?=\.\d+%))' interrogate_output.txt || echo "0")
          echo "docstring_coverage=${DOCSTRING_COVERAGE}" >> $GITHUB_OUTPUT
        continue-on-error: true

      - name: üìö Check documentation files coverage
        id: docs-coverage
        run: |
          # üî• COMPREHENSIVE DOCUMENTATION COVERAGE INVESTIGATION üî•
          total_files=0
          documented_files=0
          missing_files=()
          pr_files=()
          pr_missing_files=()

          # Get list of changed files in this PR (if applicable)
          if [ "${{ github.event_name }}" == "pull_request" ]; then
            git fetch origin ${{ github.base_ref }}
            changed_files=$(git diff --name-only origin/${{ github.base_ref }}...HEAD | grep -E '\.(ts|tsx|js|jsx)$' | grep '^src/' || true)
          else
            changed_files=""
          fi

          # üìä FULL CODEBASE DOCUMENTATION AUDIT üìä
          echo "## üö® BREAKING: Documentation Coverage Scandal Exposed! üö®" > coverage_report.md
          echo "" >> coverage_report.md
          echo "### üì∞ **EXCLUSIVE INVESTIGATION REVEALS SHOCKING TRUTH ABOUT CODE DOCUMENTATION!** üì∞" >> coverage_report.md
          echo "" >> coverage_report.md

          # Check ALL TypeScript/JavaScript files in src/
          for file in $(find src/ -name "*.ts" -o -name "*.tsx" -o -name "*.js" -o -name "*.jsx" 2>/dev/null || true); do
            if [ -f "$file" ]; then
              total_files=$((total_files + 1))
              
              # Get the base filename without extension and convert to lowercase
              base_name=$(basename "$file" | sed 's/\.[^.]*$//' | tr '[:upper:]' '[:lower:]')
              
              # Check for documentation in categorized structure
              doc_found=false
              
              # Check different documentation categories
              for doc_pattern in "DOCS/services/${base_name}.md" "DOCS/components/${base_name}.md" "DOCS/api/${base_name}.md" "DOCS/utils/${base_name}.md" "DOCS/hooks/${base_name}.md"; do
                if [ -f "$doc_pattern" ]; then
                  # Skip auto-generated stubs that haven't been filled out
                  if ! grep -q "Documentation Needed.*This file was automatically generated" "$doc_pattern"; then
                    doc_found=true
                    break
                  fi
                fi
              done
              
              # Also check the mirror structure as fallback
              mirror_doc_file="DOCS/${file%.*}.md"
              if [ -f "$mirror_doc_file" ] && ! grep -q "Documentation Needed.*This file was automatically generated" "$mirror_doc_file"; then
                doc_found=true
              fi
              
              if [ "$doc_found" = true ]; then
                documented_files=$((documented_files + 1))
              else
                missing_files+=("$file")
              fi
              
              # Check if this file is in the PR
              if [ -n "$changed_files" ] && echo "$changed_files" | grep -q "^$file$"; then
                pr_files+=("$file")
                if [ "$doc_found" = false ]; then
                  pr_missing_files+=("$file")
                fi
              fi
            fi
          done

          # Calculate coverage
          if [ $total_files -eq 0 ]; then
            DOC_COVERAGE=100
          else
            DOC_COVERAGE=$((documented_files * 100 / total_files))
          fi

          echo "doc_coverage=${DOC_COVERAGE}" >> $GITHUB_OUTPUT
          echo "total_files=${total_files}" >> $GITHUB_OUTPUT
          echo "documented_files=${documented_files}" >> $GITHUB_OUTPUT
          echo "pr_files_count=${#pr_files[@]}" >> $GITHUB_OUTPUT
          echo "pr_missing_count=${#pr_missing_files[@]}" >> $GITHUB_OUTPUT

          if [ $DOC_COVERAGE -ge 85 ]; then
            echo "docs_coverage_passed=true" >> $GITHUB_OUTPUT
          else
            echo "docs_coverage_passed=false" >> $GITHUB_OUTPUT
          fi

          # Generate professional coverage report
          echo "### üìä Documentation Coverage Statistics" >> coverage_report.md
          echo "" >> coverage_report.md
          echo "| Metric | Count | Percentage |" >> coverage_report.md
          echo "|--------|-------|------------|" >> coverage_report.md
          echo "| Total Source Files | ${total_files} | 100% |" >> coverage_report.md
          echo "| Documented Files | ${documented_files} | ${DOC_COVERAGE}% |" >> coverage_report.md
          echo "| Missing Documentation | ${#missing_files[@]} | $((100 - DOC_COVERAGE))% |" >> coverage_report.md
          echo "" >> coverage_report.md

          # Generate missing files report
          if [ ${#missing_files[@]} -gt 0 ]; then
            echo "### ‚ö†Ô∏è Files Missing Documentation (${#missing_files[@]} files)" >> coverage_report.md
            echo "" >> coverage_report.md
            echo "The following source files need corresponding documentation files:" >> coverage_report.md
            echo "" >> coverage_report.md
            echo "| Source File | Required Documentation | Status |" >> coverage_report.md
            echo "|-------------|------------------------|--------|" >> coverage_report.md
            printf '%s\n' "${missing_files[@]}" | while read -r line; do
              src_file="$line"
              base_name=$(basename "$src_file" | sed 's/\.[^.]*$//' | tr '[:upper:]' '[:lower:]')
              
              # Suggest appropriate documentation category based on file path
              if [[ "$src_file" == *"/services/"* ]]; then
                suggested_doc="DOCS/services/${base_name}.md"
              elif [[ "$src_file" == *"/components/"* ]]; then
                suggested_doc="DOCS/components/${base_name}.md"
              elif [[ "$src_file" == *"/api/"* ]] || [[ "$src_file" == *"/route.ts" ]]; then
                suggested_doc="DOCS/api/${base_name}.md"
              elif [[ "$src_file" == *"/utils/"* ]]; then
                suggested_doc="DOCS/utils/${base_name}.md"
              elif [[ "$src_file" == *"/hooks/"* ]]; then
                suggested_doc="DOCS/hooks/${base_name}.md"
              else
                suggested_doc="DOCS/${src_file%.*}.md"
              fi
              
              echo "| \`${src_file}\` | \`${suggested_doc}\` | ‚ùå Missing |" >> coverage_report.md
            done
            echo "" >> coverage_report.md
            echo "üìù Please create documentation files for these source files to improve coverage." >> coverage_report.md
          else
            echo "### ‚úÖ Perfect Documentation Coverage!" >> coverage_report.md
            echo "" >> coverage_report.md
            echo "üéâ All source files have corresponding documentation files." >> coverage_report.md
          fi
          echo "" >> coverage_report.md

          # Generate PR-specific professional report
          if [ "${{ github.event_name }}" == "pull_request" ]; then
            echo "### üìã PR Documentation Status" > pr_coverage_report.md
            echo "" >> pr_coverage_report.md
            echo "**üìÅ Files Changed in This PR:** ${#pr_files[@]}" >> pr_coverage_report.md
            echo "**üìù Missing Documentation:** ${#pr_missing_files[@]}" >> pr_coverage_report.md
            echo "" >> pr_coverage_report.md

            if [ ${#pr_missing_files[@]} -gt 0 ]; then
              echo "### ‚ö†Ô∏è PR Contains Undocumented Files" >> pr_coverage_report.md
              echo "" >> pr_coverage_report.md
              echo "This PR modifies files that are missing corresponding documentation:" >> pr_coverage_report.md
              echo "" >> pr_coverage_report.md
              echo "| File in PR | Required Documentation | Action Needed |" >> pr_coverage_report.md
              echo "|------------|------------------------|---------------|" >> pr_coverage_report.md
              printf '%s\n' "${pr_missing_files[@]}" | while read -r line; do
                src_file="$line"
                base_name=$(basename "$src_file" | sed 's/\.[^.]*$//' | tr '[:upper:]' '[:lower:]')
                
                # Suggest appropriate documentation category based on file path
                if [[ "$src_file" == *"/services/"* ]]; then
                  suggested_doc="DOCS/services/${base_name}.md"
                elif [[ "$src_file" == *"/components/"* ]]; then
                  suggested_doc="DOCS/components/${base_name}.md"
                elif [[ "$src_file" == *"/api/"* ]] || [[ "$src_file" == *"/route.ts" ]]; then
                  suggested_doc="DOCS/api/${base_name}.md"
                elif [[ "$src_file" == *"/utils/"* ]]; then
                  suggested_doc="DOCS/utils/${base_name}.md"
                elif [[ "$src_file" == *"/hooks/"* ]]; then
                  suggested_doc="DOCS/hooks/${base_name}.md"
                else
                  suggested_doc="DOCS/${src_file%.*}.md"
                fi
                
                echo "| \`${src_file}\` | \`${suggested_doc}\` | üìù Create docs |" >> pr_coverage_report.md
              done
              echo "" >> pr_coverage_report.md
              echo "üìã Please create these documentation files to maintain code quality standards." >> pr_coverage_report.md
            else
              if [ ${#pr_files[@]} -gt 0 ]; then
                echo "### ‚úÖ All PR Files Have Documentation" >> pr_coverage_report.md
                echo "" >> pr_coverage_report.md
                echo "üéâ Every file in this PR has proper documentation coverage:" >> pr_coverage_report.md
                echo "" >> pr_coverage_report.md
                echo "| File in PR | Documentation | Status |" >> pr_coverage_report.md
                echo "|------------|---------------|--------|" >> pr_coverage_report.md
                printf '%s\n' "${pr_files[@]}" | while read -r line; do
                  src_file="$line"
                  base_name=$(basename "$src_file" | sed 's/\.[^.]*$//' | tr '[:upper:]' '[:lower:]')
                  
                  # Find the actual documentation file
                  actual_doc=""
                  for doc_pattern in "DOCS/services/${base_name}.md" "DOCS/components/${base_name}.md" "DOCS/api/${base_name}.md" "DOCS/utils/${base_name}.md" "DOCS/hooks/${base_name}.md" "DOCS/${src_file%.*}.md"; do
                    if [ -f "$doc_pattern" ] && ! grep -q "Documentation Needed.*This file was automatically generated" "$doc_pattern"; then
                      actual_doc="$doc_pattern"
                      break
                    fi
                  done
                  
                  if [ -n "$actual_doc" ]; then
                    echo "| \`${src_file}\` | \`${actual_doc}\` | ‚úÖ Documented |" >> pr_coverage_report.md
                  else
                    echo "| \`${src_file}\` | N/A | ‚ùå Missing |" >> pr_coverage_report.md
                  fi
                done
              else
                echo "### ‚ÑπÔ∏è No Source Files Changed in This PR" >> pr_coverage_report.md
                echo "" >> pr_coverage_report.md
                echo "This PR doesn't modify any source files requiring documentation." >> pr_coverage_report.md
              fi
            fi
          fi
        continue-on-error: true

      - name: üé® Generate SonarCloud compatible metrics
        id: generate-metrics
        run: |
          # Calculate overall documentation coverage (weighted average)
          DOC_COVERAGE="${{ steps.docs-coverage.outputs.doc_coverage }}"
          DOCSTRING_COVERAGE="${{ steps.interrogate.outputs.docstring_coverage }}"
          OVERALL_COVERAGE=$(python -c "print(int(($DOC_COVERAGE * 0.6) + ($DOCSTRING_COVERAGE * 0.4)))")

          echo "overall_coverage=${OVERALL_COVERAGE}" >> $GITHUB_OUTPUT

                    # Create SonarCloud-compatible reports
          mkdir -p coverage

          # Create dynamic SonarCloud test execution XML with actual coverage data
          echo '<?xml version="1.0" encoding="UTF-8"?>' > coverage/documentation-test-execution.xml
          echo '<testExecutions version="1">' >> coverage/documentation-test-execution.xml
          echo '  <file path="tests/documentation-coverage.test.js">' >> coverage/documentation-test-execution.xml

          # Documentation Files Test Case (dynamic based on actual coverage)
          if [ $DOC_COVERAGE -lt 85 ]; then
            echo "    <testCase name=\"Documentation Files Coverage (${DOC_COVERAGE}%)\" duration=\"100\">" >> coverage/documentation-test-execution.xml
            echo "      <failure message=\"Documentation files coverage ${DOC_COVERAGE}% below 85% threshold\"/>" >> coverage/documentation-test-execution.xml
            echo "    </testCase>" >> coverage/documentation-test-execution.xml
          else
            echo "    <testCase name=\"Documentation Files Coverage (${DOC_COVERAGE}%)\" duration=\"100\"/>" >> coverage/documentation-test-execution.xml
          fi

          # Python Docstring Test Case (dynamic based on actual coverage)
          if [ $DOCSTRING_COVERAGE -lt 85 ]; then
            echo "    <testCase name=\"Python Docstring Coverage (${DOCSTRING_COVERAGE}%)\" duration=\"50\">" >> coverage/documentation-test-execution.xml
            echo "      <failure message=\"Python docstring coverage ${DOCSTRING_COVERAGE}% below 85% threshold\"/>" >> coverage/documentation-test-execution.xml
            echo "    </testCase>" >> coverage/documentation-test-execution.xml
          else
            echo "    <testCase name=\"Python Docstring Coverage (${DOCSTRING_COVERAGE}%)\" duration=\"50\"/>" >> coverage/documentation-test-execution.xml
          fi

          # Overall Documentation Coverage Test Case (dynamic based on actual coverage)
          if [ $OVERALL_COVERAGE -lt 85 ]; then
            echo "    <testCase name=\"Overall Documentation Coverage (${OVERALL_COVERAGE}%)\" duration=\"75\">" >> coverage/documentation-test-execution.xml
            echo "      <failure message=\"Overall documentation coverage ${OVERALL_COVERAGE}% below 85% threshold\"/>" >> coverage/documentation-test-execution.xml
            echo "    </testCase>" >> coverage/documentation-test-execution.xml
          else
            echo "    <testCase name=\"Overall Documentation Coverage (${OVERALL_COVERAGE}%)\" duration=\"75\"/>" >> coverage/documentation-test-execution.xml
          fi

          echo '  </file>' >> coverage/documentation-test-execution.xml
          echo '</testExecutions>' >> coverage/documentation-test-execution.xml

          # Debug: Show generated XML content
          echo "üìã Generated test execution XML:"
          cat coverage/documentation-test-execution.xml

          # Validate XML syntax
          if command -v xmllint >/dev/null 2>&1; then
            echo "üîç Validating XML syntax..."
            xmllint --noout coverage/documentation-test-execution.xml && echo "‚úÖ XML is valid" || echo "‚ùå XML is invalid"
          fi

          # Create generic coverage report (simplified for debugging)
          DOC_COVERED=$([ $DOC_COVERAGE -ge 85 ] && echo "true" || echo "false")
          DOCSTRING_COVERED=$([ $DOCSTRING_COVERAGE -ge 85 ] && echo "true" || echo "false") 
          OVERALL_COVERED=$([ $OVERALL_COVERAGE -ge 85 ] && echo "true" || echo "false")

          echo '<?xml version="1.0" encoding="UTF-8"?>' > coverage/documentation-generic-coverage.xml
          echo '<coverage version="1">' >> coverage/documentation-generic-coverage.xml
          echo '  <file path="metrics/documentation-coverage.md">' >> coverage/documentation-generic-coverage.xml
          echo "    <lineToCover lineNumber=\"1\" covered=\"${DOC_COVERED}\"/>" >> coverage/documentation-generic-coverage.xml
          echo "    <lineToCover lineNumber=\"2\" covered=\"${DOCSTRING_COVERED}\"/>" >> coverage/documentation-generic-coverage.xml
          echo "    <lineToCover lineNumber=\"3\" covered=\"${OVERALL_COVERED}\"/>" >> coverage/documentation-generic-coverage.xml
          echo '  </file>' >> coverage/documentation-generic-coverage.xml
          echo '</coverage>' >> coverage/documentation-generic-coverage.xml

          # Debug: Show generated coverage XML content
          echo "üìä Generated coverage XML:"
          cat coverage/documentation-generic-coverage.xml

          # Validate coverage XML syntax
          if command -v xmllint >/dev/null 2>&1; then
            echo "üîç Validating coverage XML syntax..."
            xmllint --noout coverage/documentation-generic-coverage.xml && echo "‚úÖ Coverage XML is valid" || echo "‚ùå Coverage XML is invalid"
          fi

      # Upload documentation coverage artifacts for SonarCloud
      - name: üì§ Upload documentation coverage artifacts
        uses: actions/upload-artifact@v4
        with:
          name: documentation-coverage-reports
          path: |
            coverage/documentation-test-execution.xml
            coverage/documentation-generic-coverage.xml
          retention-days: 7

      - name: üí¨ Comment on PR with detailed TABLOID results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');

            const interrogatePassed = '${{ steps.interrogate.outputs.interrogate_passed }}' === 'true';
            const docsCoveragePassed = '${{ steps.docs-coverage.outputs.docs_coverage_passed }}' === 'true';
            const overallCoverage = '${{ steps.generate-metrics.outputs.overall_coverage }}';
            const docCoverage = '${{ steps.docs-coverage.outputs.doc_coverage }}';
            const docstringCoverage = '${{ steps.interrogate.outputs.docstring_coverage }}';

            const overallStatus = interrogatePassed && docsCoveragePassed ? '‚úÖ' : '‚ùå';

            let comment = `## ${overallStatus} Documentation Coverage Report\n\n`;
            comment += `### üìä Coverage Summary\n\n`;
            comment += `| Check | Status | Coverage |\n`;
            comment += `|-------|--------|----------|\n`;
            comment += `| üêç Python Docstrings | ${interrogatePassed ? '‚úÖ Passed' : '‚ùå Failed'} | ${docstringCoverage}% |\n`;
            comment += `| üìù Documentation Files | ${docsCoveragePassed ? '‚úÖ Passed' : '‚ùå Failed'} | ${docCoverage}% |\n`;
            comment += `| üéØ **Overall Coverage** | ${overallStatus} **${overallStatus === '‚úÖ' ? 'Passed' : 'Failed'}** | **${overallCoverage}%** |\n\n`;

            // Add PR-specific documentation status
            try {
              if (fs.existsSync('pr_coverage_report.md')) {
                const prReportContent = fs.readFileSync('pr_coverage_report.md', 'utf8');
                comment += `<details>\n<summary>üîç **PR Documentation Status**</summary>\n\n`;
                comment += prReportContent + '\n';
                comment += `</details>\n\n`;
              }
            } catch (error) {
              console.log('Error reading PR coverage report:', error);
            }

            // Add detailed reports in collapsible sections if there are issues
            if (!interrogatePassed) {
              comment += `<details>\n<summary>üêç **Python Docstring Details**</summary>\n\n`;
              
              try {
                if (fs.existsSync('interrogate_output.txt')) {
                  const interrogateOutput = fs.readFileSync('interrogate_output.txt', 'utf8');
                  comment += '```\n' + interrogateOutput + '\n```\n';
                } else {
                  comment += '‚ö†Ô∏è No detailed interrogate output available.\n';
                }
              } catch (error) {
                comment += '‚ùå Failed to read interrogate output.\n';
              }
              
              comment += `\n</details>\n\n`;
            }

            // Add full codebase documentation status
            if (!docsCoveragePassed) {
              comment += `<details>\n<summary>üìö **Full Codebase Documentation Coverage**</summary>\n\n`;
              
              try {
                if (fs.existsSync('coverage_report.md')) {
                  const fullReportContent = fs.readFileSync('coverage_report.md', 'utf8');
                  comment += fullReportContent + '\n';
                } else {
                  comment += `üìä **Coverage Status:** ${{ steps.docs-coverage.outputs.documented_files }} of ${{ steps.docs-coverage.outputs.total_files }} files documented\n\n`;
                  comment += `‚ö†Ô∏è Some source files are missing corresponding documentation files. `;
                  comment += `Please create documentation files in the \`DOCS/\` directory.\n\n`;
                  comment += `**üìÅ Expected Documentation Structure:**\n`;
                  comment += `- For \`src/components/Button.tsx\` ‚Üí create \`DOCS/src/components/Button.md\`\n`;
                  comment += `- For \`src/utils/helpers.ts\` ‚Üí create \`DOCS/src/utils/helpers.md\`\n`;
                }
              } catch (error) {
                comment += '‚ùå Failed to read full coverage report.\n';
              }
              
              comment += `</details>\n\n`;
            }

            comment += `### üéØ SonarCloud Integration\n`;
            comment += `üìä Coverage data will be available in the SonarCloud dashboard.\n\n`;
            comment += `---\n*üìã This report was automatically generated by the Quality Assurance workflow.*`;

            // Find existing documentation coverage comment and update/create
            const { data: comments } = await github.rest.issues.listComments({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo
            });

            const existingComment = comments.find(comment => 
              comment.body.includes('Documentation Coverage Investigation Results') ||
              comment.body.includes('Documentation Coverage Report')
            );

            if (existingComment) {
              console.log('üîÑ Updating existing documentation coverage comment...');
              await github.rest.issues.updateComment({
                comment_id: existingComment.id,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: comment
              });
            } else {
              console.log('üìù Creating new documentation coverage comment...');
              await github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: comment
              });
            }

            console.log('‚úÖ Documentation coverage comment posted successfully!');

  # SonarCloud analysis job (matches original working setup)
  sonar:
    timeout-minutes: 15
    name: SonarCloud Analysis
    needs: [playwright-tests, jest-tests, documentation-coverage]
    if: ${{ !cancelled() }} # Run even if some tests fail
    runs-on: ubuntu-latest
    environment: actions
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      # Download all workflow artifacts including documentation coverage
      - name: Download all workflow run artifacts
        continue-on-error: true
        uses: actions/download-artifact@v4

      # Install xmllint for XML validation
      - name: Install XML tools
        run: sudo apt-get update && sudo apt-get install -y libxml2-utils

      # Clear any existing SonarCloud cache and force fresh download
      - name: Clear SonarCloud cache and force fresh scanner
        run: |
          echo "üßπ Clearing SonarCloud cache..."
          rm -rf ~/.sonar/cache || true
          rm -rf /tmp/sonar-scanner-* || true
          rm -rf /home/runner/.sonar || true
          echo "‚úÖ Cache cleared"

          # Force a different cache key by creating a timestamp file
          echo "CACHE_BUSTER=$(date +%s)" >> $GITHUB_ENV

      # Debug: List downloaded artifacts
      - name: Debug artifacts
        run: |
          echo "üìÅ Downloaded artifacts:"
          find . -name "*.xml" -type f | head -20
          echo "üìä Coverage directory contents:"
          ls -la coverage/ || echo "No coverage directory found"

      # Run SonarCloud analysis with cache busting
      - name: SonarCloud Scan
        continue-on-error: true
        uses: SonarSource/sonarqube-scan-action@v5.0.0
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
          # Force fresh analysis with cache busting
          SONAR_SCANNER_OPTS: '-Dsonar.scanner.cacheEnabled=false -Dsonar.cache.dir=/tmp/sonar-cache-${{ env.CACHE_BUSTER }}'

  # Status reporting jobs that consolidate matrix results
  playwright-status:
    name: Playwright Status
    needs: playwright-tests
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Report Playwright Status
        uses: actions/github-script@v7
        with:
          script: |
            const jobs = ${{ toJson(needs.playwright-tests.result) }};
            const success = jobs === 'success';
            const skipped = jobs === 'skipped';

            console.log(`Playwright tests result: ${jobs}`);

            if (skipped) {
              console.log('‚úÖ Playwright tests were skipped');
            } else if (success) {
              console.log('‚úÖ All Playwright tests passed');
            } else {
              console.log('‚ùå Some Playwright tests failed (non-blocking)');
            }

  jest-status:
    name: Jest Status
    needs: jest-tests
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Report Jest Status
        uses: actions/github-script@v7
        with:
          script: |
            const jobs = ${{ toJson(needs.jest-tests.result) }};
            const success = jobs === 'success';

            console.log(`Jest tests result: ${jobs}`);

            if (success) {
              console.log('‚úÖ All Jest tests passed');
            } else {
              console.log('‚ùå Jest tests failed');
              process.exit(1);
            }

  # Final status job
  tests-complete:
    name: Quality Assurance Complete
    needs: [jest-status, playwright-status, documentation-coverage, sonar]
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Report Final Status
        run: |
          echo "üß™ Quality Assurance Complete"
          echo "============================"
          echo "Jest: ${{ needs.jest-status.result }}"
          echo "Playwright: ${{ needs.playwright-status.result }}"
          echo "Documentation: ${{ needs.documentation-coverage.result }}"
          echo "SonarCloud: ${{ needs.sonar.result }}"

          if [[ "${{ needs.jest-status.result }}" == "success" ]]; then
            echo "‚úÖ All required tests passed"
            if [[ "${{ needs.documentation-coverage.result }}" == "success" ]]; then
              echo "‚úÖ Documentation coverage meets requirements"
            else
              echo "‚ö†Ô∏è Documentation coverage needs attention (non-blocking)"
            fi
            if [[ "${{ needs.sonar.result }}" == "success" ]]; then
              echo "‚úÖ SonarCloud analysis completed successfully"
            else
              echo "‚ö†Ô∏è SonarCloud analysis had issues (non-blocking)"
            fi
          else
            echo "‚ùå Required tests failed"
            exit 1
          fi
