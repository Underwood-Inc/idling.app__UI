name: Quality Assurance

# Concurrency group to cancel in-progress runs on PR updates
concurrency:
  group: tests-pr-${{ github.event.pull_request.number || github.ref }}-${{ github.sha }}
  cancel-in-progress: true

# PERFORMANCE OPTIMIZATION:
# This workflow uses a shared setup job to install dependencies and browsers once,
# then caches them for reuse across all matrix jobs. This significantly reduces
# build time and resource usage compared to each matrix job installing dependencies separately.

on:
  push:
    branches: [main, master]
    paths-ignore:
      - '**.md'
      - 'docs/**'
  pull_request:
    types: [opened, synchronize, reopened]
    paths-ignore:
      - '**.md'
      - 'docs/**'

# Required permissions for GitHub Actions
permissions:
  contents: read
  actions: write
  checks: write
  pull-requests: write

# Environment variables available to all jobs
env:
  AUTH_TRUST_HOST: true
  NEXTAUTH_URL: http://localhost:3000
  # Secrets are encrypted environment variables (optional - fallbacks provided in code)
  NEXTAUTH_SECRET: ${{ secrets.NEXTAUTH_SECRET || 'fallback-secret-for-testing-only' }}
  AUTHJS_SESSION_TOKEN: ${{ secrets.AUTHJS_SESSION_TOKEN }}
  AUTHJS_CALLBACK_URL: ${{ secrets.AUTHJS_CALLBACK_URL }}
  AUTHJS_CSRF_TOKEN: ${{ secrets.AUTHJS_CSRF_TOKEN }}
  POSTGRES_HOST: ${{ secrets.POSTGRES_HOST }}
  POSTGRES_PORT: ${{ secrets.POSTGRES_PORT }}
  POSTGRES_USER: ${{ secrets.POSTGRES_USER }}
  POSTGRES_DB: ${{ secrets.POSTGRES_DB }}
  POSTGRES_PASSWORD: ${{ secrets.POSTGRES_PASSWORD }}
  POSTGRES_HOST_AUTH_METHOD: md5
  POSTGRES_INITDB_ARGS: --auth-host=md5
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
  WORKFLOW_TOKEN: ${{ secrets.WORKFLOW_TOKEN }}
  SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}

jobs:
  setup:
    timeout-minutes: 10
    name: Setup Environment
    runs-on: ubuntu-latest
    environment: actions
    outputs:
      cache-key: ${{ steps.cache.outputs.cache-hit }}
      node-version: ${{ steps.node-version.outputs.version }}
    steps:
      # Checkout code with full git history for proper versioning
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      # Setup Node.js using LTS version and output version for reuse
      - uses: actions/setup-node@v4
        id: setup-node
        with:
          node-version: lts/*
          cache: 'yarn' # Enable built-in yarn caching

      # Output Node.js version for other jobs
      - name: Get Node.js version
        id: node-version
        run: echo "version=$(node --version)" >> $GITHUB_OUTPUT

      # Install project dependencies
      - name: Install dependencies
        run: npm install -g yarn && yarn install --check-files

      # Install Playwright browsers for caching
      - name: Install Playwright browsers
        run: npx playwright install --with-deps

      # Cache dependencies and browsers to speed up future runs
      - name: Cache dependencies and browsers
        id: cache
        uses: actions/cache/save@v4
        with:
          path: |
            node_modules
            ~/.cache/playwright
            ~/.cache/ms-playwright
          key: ${{ runner.os }}-deps-browsers-${{ hashFiles('**/yarn.lock', '**/package.json') }}

  playwright-tests:
    name: Playwright Tests
    needs: setup
    runs-on: ubuntu-latest
    timeout-minutes: 30
    environment: actions
    continue-on-error: true # Make Playwright tests optional - don't fail the workflow
    strategy:
      fail-fast: false # Continue with other shards if one fails
      matrix:
        shard: [1, 2, 3] # Run tests in 3 parallel shards
    services:
      # PostgreSQL service container for E2E tests
      postgres:
        image: postgres
        env:
          # Database configuration
          POSTGRES_HOST: ${{ secrets.POSTGRES_HOST }}
          POSTGRES_PORT: ${{ secrets.POSTGRES_PORT }}
          POSTGRES_USER: ${{ secrets.POSTGRES_USER }}
          POSTGRES_DB: ${{ secrets.POSTGRES_DB }}
          POSTGRES_PASSWORD: ${{ secrets.POSTGRES_PASSWORD }}
          POSTGRES_HOST_AUTH_METHOD: md5
          POSTGRES_INITDB_ARGS: --auth-host=md5
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    steps:
      - uses: actions/checkout@v4

      # Use the same Node.js version as setup job
      - uses: actions/setup-node@v4
        with:
          node-version: lts/*
          cache: 'yarn'

      # Restore cached dependencies and browsers from setup job
      - name: Restore dependencies and browsers cache
        id: cache-restore
        uses: actions/cache/restore@v4
        with:
          path: |
            node_modules
            ~/.cache/playwright
            ~/.cache/ms-playwright
          key: ${{ runner.os }}-deps-browsers-${{ hashFiles('**/yarn.lock', '**/package.json') }}
          restore-keys: |
            ${{ runner.os }}-deps-browsers-
            ${{ runner.os }}-deps-
          fail-on-cache-miss: false

      # Install dependencies if cache miss (first run or cache eviction)
      - name: Install dependencies and browsers
        if: steps.cache-restore.outputs.cache-hit != 'true'
        run: |
          yarn install --check-files
          npx playwright install --with-deps

      # Setup test database
      - name: Run migrations
        run: psql -v POSTGRES_DB="$POSTGRES_DB" -v POSTGRES_PASSWORD="$POSTGRES_PASSWORD" -v POSTGRES_USER="$POSTGRES_USER" -f ./src/lib/scripts/000-init.sql postgresql://${{secrets.POSTGRES_USER}}:${{secrets.POSTGRES_PASSWORD}}@${{secrets.POSTGRES_HOST}}:${{secrets.POSTGRES_PORT}}

      # Run E2E tests with sharding
      - name: Run Playwright tests (Shard ${{ matrix.shard }}/3)
        run: |
          echo "::group::Running Playwright Tests (Shard ${{ matrix.shard }}/3)"
          # Create directories for each project
          mkdir -p test-results/{chromium,firefox,webkit} playwright-report

          # Run tests with reporters configured in playwright.config.ts
          IS_CI=1 IS_GITHUB_ACTIONS=1 FORCE_COLOR=1 yarn playwright test \
            --shard=${{ matrix.shard }}/3

          # Debug: Show test results
          echo "Test results directory contents:"
          ls -la test-results/
          echo "\nTest results by project:"
          for dir in test-results/*/; do
            echo "\n$dir:"
            ls -la "$dir"
          done
          echo "::endgroup::"

      # Upload test results for this shard
      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: playwright-results-${{ matrix.shard }}
          path: |
            test-results/**/*
            playwright-report/**/*
          retention-days: 30

      # Upload traces only on failure
      - name: Upload test traces on failure
        if: ${{ failure() && !cancelled() }}
        uses: actions/upload-artifact@v4
        with:
          name: playwright-traces-${{ matrix.shard }}
          path: test-results/
          retention-days: 7

  jest-tests:
    timeout-minutes: 15
    name: Jest Tests
    needs: setup
    runs-on: ubuntu-latest
    environment: actions
    strategy:
      fail-fast: false
      matrix:
        shard: [1, 2, 3] # Run tests in 3 parallel shards
    steps:
      - uses: actions/checkout@v4

      # Use the same Node.js version as setup job
      - uses: actions/setup-node@v4
        with:
          node-version: lts/*
          cache: 'yarn'

      # Restore cached dependencies from setup job
      - name: Restore dependencies cache
        id: cache-restore
        uses: actions/cache/restore@v4
        with:
          path: |
            node_modules
            ~/.cache/playwright
            ~/.cache/ms-playwright
          key: ${{ runner.os }}-deps-browsers-${{ hashFiles('**/yarn.lock', '**/package.json') }}
          restore-keys: |
            ${{ runner.os }}-deps-browsers-
            ${{ runner.os }}-deps-
          fail-on-cache-miss: false

      # Install dependencies if cache miss (first run or cache eviction)
      - name: Install dependencies
        if: steps.cache-restore.outputs.cache-hit != 'true'
        run: yarn install --check-files

      # Run unit tests with sharding
      - name: Run Jest tests (Shard ${{ matrix.shard }}/3)
        run: |
          echo "::group::Running Jest Tests (Shard ${{ matrix.shard }}/3)"
          FORCE_COLOR=1 yarn test:coverage --ci --colors --json --shard=${{ matrix.shard }}/3 --testLocationInResults --outputFile="$GITHUB_WORKSPACE/jest-results-${{ matrix.shard }}.json"
          echo "::endgroup::"

      # Upload coverage reports for each shard
      - name: Upload Jest coverage
        if: ${{ !cancelled() }}
        uses: actions/upload-artifact@v4
        with:
          name: jest-coverage-${{ matrix.shard }}
          path: coverage/
          retention-days: 30

  # SonarCloud analysis job (matches original working setup)
  sonar:
    timeout-minutes: 15
    name: SonarCloud Analysis
    needs: [playwright-tests, jest-tests]
    if: ${{ !cancelled() }} # Run even if some tests fail
    runs-on: ubuntu-latest
    environment: actions
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      # Download Jest coverage artifacts
      - name: Download Jest coverage artifacts
        continue-on-error: true
        uses: actions/download-artifact@v4
        with:
          pattern: jest-coverage-*
          merge-multiple: true

      # Download documentation coverage artifacts
      - name: Download documentation coverage artifacts
        continue-on-error: true
        uses: actions/download-artifact@v4
        with:
          name: documentation-coverage-reports
          path: coverage/

      # Install xmllint for XML validation
      - name: Install XML tools
        run: sudo apt-get update && sudo apt-get install -y libxml2-utils

      # Ensure coverage directory exists and validate XML files
      - name: Prepare coverage directory and validate XML
        run: |
          echo "üìÅ Creating coverage directory if it doesn't exist..."
          mkdir -p coverage

          echo "üìä Coverage directory contents:"
          ls -la coverage/ || echo "No coverage directory found"

          echo "üìÅ All XML files in workspace:"
          find . -name "*.xml" -type f | head -20

          # Check if documentation XML exists and validate it
          if [ -f "coverage/documentation-test-execution.xml" ]; then
            echo "‚úÖ Found documentation-test-execution.xml"
            echo "üìã XML content preview:"
            head -10 coverage/documentation-test-execution.xml
            
            # Validate XML syntax if xmllint is available
            if command -v xmllint >/dev/null 2>&1; then
              echo "üîç Validating XML syntax..."
              if xmllint --noout coverage/documentation-test-execution.xml; then
                echo "‚úÖ XML is valid"
              else
                echo "‚ùå XML is invalid - creating fallback"
                # Create a minimal valid XML file as fallback
                {
                  printf '<?xml version="1.0" encoding="UTF-8"?>\n'
                  printf '<testExecutions version="1">\n'
                  printf '  <file path="tests/documentation-coverage.test.js">\n'
                  printf '    <testCase name="Documentation Coverage Test" duration="100">\n'
                  printf '      <failure message="XML generation failed">Documentation coverage XML could not be generated properly</failure>\n'
                  printf '    </testCase>\n'
                  printf '  </file>\n'
                  printf '</testExecutions>\n'
                } > coverage/documentation-test-execution.xml
              fi
            fi
          else
            echo "‚ùå documentation-test-execution.xml not found - creating fallback"
            # Create a minimal valid XML file as fallback
            {
              printf '<?xml version="1.0" encoding="UTF-8"?>\n'
              printf '<testExecutions version="1">\n'
              printf '  <file path="tests/documentation-coverage.test.js">\n'
              printf '    <testCase name="Documentation Coverage Test" duration="100">\n'
              printf '      <failure message="XML file missing">Documentation coverage XML file was not generated or uploaded</failure>\n'
              printf '    </testCase>\n'
              printf '  </file>\n'
              printf '</testExecutions>\n'
            } > coverage/documentation-test-execution.xml
            echo "üìã Created fallback XML file"
          fi

      # Clear any existing SonarCloud cache and force fresh download
      - name: Clear SonarCloud cache and force fresh scanner
        run: |
          echo "üßπ Clearing SonarCloud cache..."
          rm -rf ~/.sonar/cache || true
          rm -rf /tmp/sonar-scanner-* || true
          rm -rf /home/runner/.sonar || true
          echo "‚úÖ Cache cleared"

          # Force a different cache key by creating a timestamp file
          echo "CACHE_BUSTER=$(date +%s)" >> $GITHUB_ENV

      # Run SonarCloud analysis with cache busting
      - name: SonarCloud Scan
        continue-on-error: true
        uses: SonarSource/sonarqube-scan-action@v5.0.0
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
          # Force fresh analysis with cache busting
          SONAR_SCANNER_OPTS: '-Dsonar.scanner.cacheEnabled=false -Dsonar.cache.dir=/tmp/sonar-cache-${{ env.CACHE_BUSTER }}'

      # Add SonarCloud badges to PR description
      - name: üìä Update PR with SonarCloud badges
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const projectKey = 'Underwood-Inc_idling.app__UI';
            const prNumber = context.issue.number;

            // Generate SonarCloud badge URLs for this specific PR
            const qualityGateBadge = `https://sonarcloud.io/api/project_badges/measure?project=${projectKey}&metric=alert_status&pullRequest=${prNumber}`;
            const bugsBadge = `https://sonarcloud.io/api/project_badges/measure?project=${projectKey}&metric=bugs&pullRequest=${prNumber}`;
            const codeSmellsBadge = `https://sonarcloud.io/api/project_badges/measure?project=${projectKey}&metric=code_smells&pullRequest=${prNumber}`;
            const coverageBadge = `https://sonarcloud.io/api/project_badges/measure?project=${projectKey}&metric=coverage&pullRequest=${prNumber}`;
            const duplicatedLinesBadge = `https://sonarcloud.io/api/project_badges/measure?project=${projectKey}&metric=duplicated_lines_density&pullRequest=${prNumber}`;
            const linesOfCodeBadge = `https://sonarcloud.io/api/project_badges/measure?project=${projectKey}&metric=ncloc&pullRequest=${prNumber}`;
            const reliabilityBadge = `https://sonarcloud.io/api/project_badges/measure?project=${projectKey}&metric=reliability_rating&pullRequest=${prNumber}`;
            const securityBadge = `https://sonarcloud.io/api/project_badges/measure?project=${projectKey}&metric=security_rating&pullRequest=${prNumber}`;
            const maintainabilityBadge = `https://sonarcloud.io/api/project_badges/measure?project=${projectKey}&metric=sqale_rating&pullRequest=${prNumber}`;

            const sonarCloudUrl = `https://sonarcloud.io/summary/new_code?id=${projectKey}&pullRequest=${prNumber}`;

            // Create SonarCloud badges section
            const sonarBadgesSection = `## üîç SonarCloud Analysis\n\n` +
              `[![Quality Gate Status](${qualityGateBadge})](${sonarCloudUrl})\n` +
              `[![Bugs](${bugsBadge})](${sonarCloudUrl})\n` +
              `[![Code Smells](${codeSmellsBadge})](${sonarCloudUrl})\n` +
              `[![Coverage](${coverageBadge})](${sonarCloudUrl})\n` +
              `[![Duplicated Lines (%)](${duplicatedLinesBadge})](${sonarCloudUrl})\n` +
              `[![Lines of Code](${linesOfCodeBadge})](${sonarCloudUrl})\n` +
              `[![Reliability Rating](${reliabilityBadge})](${sonarCloudUrl})\n` +
              `[![Security Rating](${securityBadge})](${sonarCloudUrl})\n` +
              `[![Maintainability Rating](${maintainabilityBadge})](${sonarCloudUrl})\n\n` +
              `[üìä View Detailed Analysis on SonarCloud](${sonarCloudUrl})\n\n` +
              `---\n\n`;

            // Get current PR description
            const { data: pr } = await github.rest.pulls.get({
              owner: context.repo.owner,
              repo: context.repo.repo,
              pull_number: prNumber
            });

            let currentDescription = pr.body || '';

            // Remove existing SonarCloud section if present
            currentDescription = currentDescription.replace(
              /## üîç SonarCloud Analysis.*?---\n\n/s,
              ''
            );

            // Add SonarCloud section at the top (after documentation coverage if present)
            let newDescription;
            if (currentDescription.includes('## üìö Documentation Coverage Status')) {
              // Insert after documentation coverage section
              newDescription = currentDescription.replace(
                /(## üìö Documentation Coverage Status.*?---\n\n)/s,
                `$1${sonarBadgesSection}`
              );
            } else {
              // Add at the very top
              newDescription = sonarBadgesSection + currentDescription.trim();
            }

            // Update PR description
            await github.rest.pulls.update({
              owner: context.repo.owner,
              repo: context.repo.repo,
              pull_number: prNumber,
              body: newDescription
            });

            console.log('‚úÖ Updated PR description with SonarCloud badges');

  # Status reporting jobs that consolidate matrix results
  playwright-status:
    name: Playwright Status
    needs: playwright-tests
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Report Playwright Status
        uses: actions/github-script@v7
        with:
          script: |
            const jobs = ${{ toJson(needs.playwright-tests.result) }};
            const success = jobs === 'success';
            const skipped = jobs === 'skipped';

            console.log(`Playwright tests result: ${jobs}`);

            if (skipped) {
              console.log('‚úÖ Playwright tests were skipped');
            } else if (success) {
              console.log('‚úÖ All Playwright tests passed');
            } else {
              console.log('‚ùå Some Playwright tests failed (non-blocking)');
            }

  jest-status:
    name: Jest Status
    needs: jest-tests
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Report Jest Status
        uses: actions/github-script@v7
        with:
          script: |
            const jobs = ${{ toJson(needs.jest-tests.result) }};
            const success = jobs === 'success';

            console.log(`Jest tests result: ${jobs}`);

            if (success) {
              console.log('‚úÖ All Jest tests passed');
            } else {
              console.log('‚ùå Jest tests failed');
              process.exit(1);
            }

  # Final status job
  tests-complete:
    name: Quality Assurance Complete
    needs: [jest-status, playwright-status, sonar]
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Report Final Status
        run: |
          echo "üß™ Quality Assurance Complete"
          echo "============================"
          echo "Jest: ${{ needs.jest-status.result }}"
          echo "Playwright: ${{ needs.playwright-status.result }}"
          echo "SonarCloud: ${{ needs.sonar.result }}"

          if [[ "${{ needs.jest-status.result }}" == "success" ]]; then
            echo "‚úÖ All required tests passed"
              echo "‚úÖ Documentation coverage meets requirements"
            else
              echo "‚ö†Ô∏è Documentation coverage needs attention (non-blocking)"
            fi
            if [[ "${{ needs.sonar.result }}" == "success" ]]; then
              echo "‚úÖ SonarCloud analysis completed successfully"
            else
              echo "‚ö†Ô∏è SonarCloud analysis had issues (non-blocking)"
            fi
          else
            echo "‚ùå Required tests failed"
            exit 1
          fi
