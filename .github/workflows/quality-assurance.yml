name: Quality Assurance

# Concurrency group to cancel in-progress runs on PR updates
concurrency:
  group: tests-pr-${{ github.event.pull_request.number || github.ref }}-${{ github.sha }}
  cancel-in-progress: true

# PERFORMANCE OPTIMIZATION:
# This workflow uses a shared setup job to install dependencies and browsers once,
# then caches them for reuse across all matrix jobs. This significantly reduces
# build time and resource usage compared to each matrix job installing dependencies separately.

on:
  push:
    branches: [main, master]
    paths-ignore:
      - '**.md'
      - 'docs/**'
  pull_request:
    types: [opened, synchronize, reopened]
    paths-ignore:
      - '**.md'
      - 'docs/**'

# Required permissions for GitHub Actions
permissions:
  contents: read
  actions: write
  checks: write
  pull-requests: write
  pages: write
  id-token: write

# Environment variables available to all jobs
env:
  AUTH_TRUST_HOST: true
  NEXTAUTH_URL: http://localhost:3000
  # Secrets are encrypted environment variables (optional - fallbacks provided in code)
  NEXTAUTH_SECRET: ${{ secrets.NEXTAUTH_SECRET || 'fallback-secret-for-testing-only' }}
  AUTHJS_SESSION_TOKEN: ${{ secrets.AUTHJS_SESSION_TOKEN }}
  AUTHJS_CALLBACK_URL: ${{ secrets.AUTHJS_CALLBACK_URL }}
  AUTHJS_CSRF_TOKEN: ${{ secrets.AUTHJS_CSRF_TOKEN }}
  POSTGRES_HOST: ${{ secrets.POSTGRES_HOST }}
  POSTGRES_PORT: ${{ secrets.POSTGRES_PORT }}
  POSTGRES_USER: ${{ secrets.POSTGRES_USER }}
  POSTGRES_DB: ${{ secrets.POSTGRES_DB }}
  POSTGRES_PASSWORD: ${{ secrets.POSTGRES_PASSWORD }}
  POSTGRES_HOST_AUTH_METHOD: md5
  POSTGRES_INITDB_ARGS: --auth-host=md5
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
  WORKFLOW_TOKEN: ${{ secrets.WORKFLOW_TOKEN }}
  SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}

jobs:
  setup:
    timeout-minutes: 10
    name: Setup Environment
    runs-on: ubuntu-latest
    environment: actions
    outputs:
      cache-key: ${{ steps.cache.outputs.cache-hit }}
      node-version: ${{ steps.node-version.outputs.version }}
    steps:
      # Checkout code with full git history for proper versioning
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      # Setup Node.js using LTS version and enable Corepack
      - uses: actions/setup-node@v4
        id: setup-node
        with:
          node-version: lts/*

      # Enable Corepack to use packageManager from package.json
      - name: Enable Corepack
        run: |
          corepack enable
          corepack install

      # Output Node.js version for other jobs
      - name: Get Node.js version
        id: node-version
        run: echo "version=$(node --version)" >> $GITHUB_OUTPUT

      # Install project dependencies using pnpm (as specified in package.json)
      - name: Install dependencies
        run: pnpm install

      # Install Playwright browsers for caching
      - name: Install Playwright browsers
        run: pnpm exec playwright install --with-deps

      # Cache dependencies and browsers to speed up future runs
      - name: Cache dependencies and browsers
        id: cache
        uses: actions/cache/save@v4
        with:
          path: |
            node_modules
            ~/.cache/playwright
            ~/.cache/ms-playwright
          key: ${{ runner.os }}-deps-browsers-${{ hashFiles('**/pnpm-lock.yaml', '**/package.json') }}

  playwright-tests:
    name: Playwright Tests
    needs: setup
    runs-on: ubuntu-latest
    timeout-minutes: 30
    environment: actions
    continue-on-error: true # Make Playwright tests optional - don't fail the workflow
    strategy:
      fail-fast: false # Continue with other shards if one fails
      matrix:
        shard: [1, 2, 3] # Run tests in 3 parallel shards
    services:
      # PostgreSQL service container for E2E tests
      postgres:
        image: postgres
        env:
          # Database configuration
          POSTGRES_HOST: ${{ secrets.POSTGRES_HOST }}
          POSTGRES_PORT: ${{ secrets.POSTGRES_PORT }}
          POSTGRES_USER: ${{ secrets.POSTGRES_USER }}
          POSTGRES_DB: ${{ secrets.POSTGRES_DB }}
          POSTGRES_PASSWORD: ${{ secrets.POSTGRES_PASSWORD }}
          POSTGRES_HOST_AUTH_METHOD: md5
          POSTGRES_INITDB_ARGS: --auth-host=md5
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    steps:
      - uses: actions/checkout@v4

      # Use the same Node.js version as setup job
      - uses: actions/setup-node@v4
        with:
          node-version: lts/*

      # Enable Corepack to use packageManager from package.json
      - name: Enable Corepack
        run: |
          corepack enable
          corepack install

      # Restore cached dependencies and browsers from setup job
      - name: Restore dependencies and browsers cache
        id: cache-restore
        uses: actions/cache/restore@v4
        with:
          path: |
            node_modules
            ~/.cache/playwright
            ~/.cache/ms-playwright
          key: ${{ runner.os }}-deps-browsers-${{ hashFiles('**/pnpm-lock.yaml', '**/package.json') }}
          restore-keys: |
            ${{ runner.os }}-deps-browsers-
            ${{ runner.os }}-deps-
          fail-on-cache-miss: false

      # Install dependencies if cache miss (first run or cache eviction)
      - name: Install dependencies and browsers
        if: steps.cache-restore.outputs.cache-hit != 'true'
        run: |
          pnpm install
          pnpm exec playwright install --with-deps

      # Setup test database
      - name: Run migrations
        run: psql -v POSTGRES_DB="$POSTGRES_DB" -v POSTGRES_PASSWORD="$POSTGRES_PASSWORD" -v POSTGRES_USER="$POSTGRES_USER" -f ./src/lib/scripts/000-init.sql postgresql://${{secrets.POSTGRES_USER}}:${{secrets.POSTGRES_PASSWORD}}@${{secrets.POSTGRES_HOST}}:${{secrets.POSTGRES_PORT}}

      # Run E2E tests with sharding
      - name: Run Playwright tests (Shard ${{ matrix.shard }}/3)
        run: |
          echo "::group::Running Playwright Tests (Shard ${{ matrix.shard }}/3)"
          # Create directories for each project
          mkdir -p test-results/{chromium,firefox,webkit} playwright-report

          # Run tests with reporters configured in playwright.config.ts
          IS_CI=1 IS_GITHUB_ACTIONS=1 FORCE_COLOR=1 pnpm playwright test \
            --shard=${{ matrix.shard }}/3

          # Debug: Show test results
          echo "Test results directory contents:"
          ls -la test-results/
          echo "\nTest results by project:"
          for dir in test-results/*/; do
            echo "\n$dir:"
            ls -la "$dir"
          done
          echo "::endgroup::"

      # Upload test results for this shard
      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: playwright-results-${{ matrix.shard }}
          path: |
            test-results/**/*
            playwright-report/**/*
          retention-days: 30

      # Upload traces only on failure
      - name: Upload test traces on failure
        if: ${{ failure() && !cancelled() }}
        uses: actions/upload-artifact@v4
        with:
          name: playwright-traces-${{ matrix.shard }}
          path: test-results/
          retention-days: 7

  documentation-coverage:
    timeout-minutes: 10
    name: Documentation Coverage
    needs: setup
    runs-on: ubuntu-latest
    environment: actions
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      # Setup Node.js for highlight.js dependency
      - uses: actions/setup-node@v4
        with:
          node-version: lts/*

      # Enable Corepack to use packageManager from package.json
      - name: Enable Corepack
        run: |
          corepack enable
          corepack install

      # Restore cached dependencies from setup job
      - name: Restore dependencies cache
        uses: actions/cache/restore@v4
        with:
          path: |
            node_modules
          key: ${{ runner.os }}-deps-browsers-${{ hashFiles('**/pnpm-lock.yaml', '**/package.json') }}
          restore-keys: |
            ${{ runner.os }}-deps-browsers-
            ${{ runner.os }}-deps-
          fail-on-cache-miss: false

      # Install dependencies if cache miss
      - name: Install dependencies
        if: steps.cache-restore.outputs.cache-hit != 'true'
        run: pnpm install

      # Setup Python for documentation coverage analysis
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      # Install Python dependencies for documentation analysis
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install interrogate

      # Run documentation coverage analysis with all formats and syntax highlighting
      - name: Run documentation coverage analysis
        run: |
          echo "📚 Running documentation coverage analysis with syntax highlighting..."

          # Generate all format reports with syntax highlighting
          python scripts/check-docs-coverage.py --format json --output doc-coverage-report.json
          python scripts/check-docs-coverage.py --format markdown --output doc-coverage-report.md
          python scripts/check-docs-coverage.py --format html --output documentation-coverage-report.html
          python scripts/check-docs-coverage.py --format csv --output doc-coverage-report.csv

          # Extract coverage percentage for badge generation
          DOC_COVERAGE=$(python -c "import json; data=json.load(open('doc-coverage-report.json')); print(int(data['coverage_percentage']))")
          echo "DOC_COVERAGE=$DOC_COVERAGE" >> $GITHUB_ENV

          # Generate console report for logs
          echo "📊 Documentation Coverage Report:"
          python scripts/check-docs-coverage.py --format console

      # Run PR-specific documentation coverage analysis
      - name: Run PR-specific documentation coverage analysis
        if: github.event_name == 'pull_request'
        env:
          PR_NUMBER: ${{ github.event.pull_request.number }}
          PR_TITLE: ${{ github.event.pull_request.title }}
          PR_BASE_REF: origin/${{ github.event.pull_request.base.ref }}
          PR_HEAD_REF: ${{ github.event.pull_request.head.sha }}
          PR_AUTHOR: ${{ github.event.pull_request.user.login }}
        run: |
          echo "🔍 Running PR-specific documentation coverage analysis..."
          echo "📍 PR Number: ${{ github.event.pull_request.number }}"
          echo "📍 Base ref: origin/${{ github.event.pull_request.base.ref }}"
          echo "📍 Head ref: ${{ github.event.pull_request.head.sha }}"
          echo "📍 Current branch: $(git branch --show-current)"
          echo "📍 Available branches: $(git branch -a | head -5)"

          # Ensure we have the latest refs
          git fetch origin ${{ github.event.pull_request.base.ref }}:${{ github.event.pull_request.base.ref }} || true
          git fetch origin +refs/pull/${{ github.event.pull_request.number }}/head:pr-${{ github.event.pull_request.number }} || true

          # Generate PR-specific reports with better error handling
          python scripts/check-pr-docs-coverage.py --format json --output pr-doc-coverage-report.json --base-ref origin/${{ github.event.pull_request.base.ref }} --head-ref ${{ github.event.pull_request.head.sha }} --pr-number ${{ github.event.pull_request.number }} || echo "PR JSON report failed"
          python scripts/check-pr-docs-coverage.py --format markdown --output pr-doc-coverage-report.md --base-ref origin/${{ github.event.pull_request.base.ref }} --head-ref ${{ github.event.pull_request.head.sha }} --pr-number ${{ github.event.pull_request.number }} || echo "PR Markdown report failed"
          python scripts/check-pr-docs-coverage.py --format html --output pr-documentation-coverage-report.html --base-ref origin/${{ github.event.pull_request.base.ref }} --head-ref ${{ github.event.pull_request.head.sha }} --pr-number ${{ github.event.pull_request.number }} || echo "PR HTML report failed"
          python scripts/check-pr-docs-coverage.py --format csv --output pr-doc-coverage-report.csv --base-ref origin/${{ github.event.pull_request.base.ref }} --head-ref ${{ github.event.pull_request.head.sha }} --pr-number ${{ github.event.pull_request.number }} || echo "PR CSV report failed"

          # Check if PR report was generated successfully
          if [ -f "pr-doc-coverage-report.json" ]; then
            echo "✅ PR documentation coverage report generated successfully"
            echo "📊 Report size: $(wc -c < pr-doc-coverage-report.json) bytes"
            echo "📊 Report preview: $(head -3 pr-doc-coverage-report.json)"
          else
            echo "❌ PR documentation coverage report was not generated"
          fi

          # Extract PR coverage percentage for badge generation
          PR_DOC_COVERAGE=$(python -c "import json; data=json.load(open('pr-doc-coverage-report.json')); print(int(data['coverage_percentage']))" 2>/dev/null || echo "100")
          echo "PR_DOC_COVERAGE=$PR_DOC_COVERAGE" >> $GITHUB_ENV

          # Generate console report for logs
          echo "📊 PR Documentation Coverage Report:"
          python scripts/check-pr-docs-coverage.py --format console --base-ref origin/${{ github.event.pull_request.base.ref }} --head-ref ${{ github.event.pull_request.head.sha }} --pr-number ${{ github.event.pull_request.number }} || echo "PR console report failed"

      # Update documentation site badge (only on main/master branch)
      - name: Update Docusaurus documentation badge
        if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'
        run: |
          # Determine badge color based on coverage
          COVERAGE=${{ env.DOC_COVERAGE }}
          if [ $COVERAGE -ge 90 ]; then
            BADGE_COLOR="brightgreen"
          elif [ $COVERAGE -ge 75 ]; then
            BADGE_COLOR="green"
          elif [ $COVERAGE -ge 60 ]; then
            BADGE_COLOR="yellow"
          elif [ $COVERAGE -ge 40 ]; then
            BADGE_COLOR="orange"
          else
            BADGE_COLOR="red"
          fi

          # Create badge URL
          BADGE_URL="https://img.shields.io/badge/Documentation%20Coverage-${COVERAGE}%25-${BADGE_COLOR}?style=flat&logo=gitbook&logoColor=white"

                    # Update the documentation site badge
          python3 scripts/update-docusaurus-badge.py --badge-url "$BADGE_URL" --coverage $COVERAGE

          echo "🎨 Updated documentation site badge: ${COVERAGE}% coverage (${BADGE_COLOR})"

      # Commit and push badge updates (only on main/master branch)
      - name: Commit documentation badge updates
        if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'
        run: |
          # Configure git
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"

          # Check if there are changes to commit
          if git diff --quiet src/index.md; then
            echo "📝 No changes to documentation badge - already up to date"
          else
            echo "📝 Committing documentation badge updates..."
            git add src/index.md
            git commit -m "docs: update documentation coverage badge to ${{ env.DOC_COVERAGE }}%

            [skip ci]"
            git push
            echo "✅ Successfully updated and pushed documentation badge"
          fi

      # Upload documentation coverage reports as artifacts
      - name: Upload documentation coverage reports
        uses: actions/upload-artifact@v4
        with:
          name: documentation-coverage-reports
          path: |
            doc-coverage-report.json
            doc-coverage-report.md
            documentation-coverage-report.html
            doc-coverage-report.csv
            pr-doc-coverage-report.json
            pr-doc-coverage-report.md
            pr-documentation-coverage-report.html
            pr-doc-coverage-report.csv
          retention-days: 30

      # Comment on PR with documentation coverage results and artifact links
      - name: Comment on PR with documentation coverage and artifacts
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');

            // Read the markdown report
            let reportContent = '';
            try {
              reportContent = fs.readFileSync('doc-coverage-report.md', 'utf8');
            } catch (error) {
              reportContent = 'Documentation coverage report could not be generated.';
            }

            // Read the JSON report for structured data
            let jsonReport = null;
            try {
              jsonReport = JSON.parse(fs.readFileSync('doc-coverage-report.json', 'utf8'));
            } catch (error) {
              console.log('Could not parse JSON report:', error);
            }

            // Read the PR-specific JSON report if it exists
            let prJsonReport = null;
            try {
              prJsonReport = JSON.parse(fs.readFileSync('pr-doc-coverage-report.json', 'utf8'));
            } catch (error) {
              console.log('Could not parse PR JSON report:', error);
            }

            // Determine badge color based on total coverage
            const coverage = jsonReport ? jsonReport.coverage_percentage : 0;
            let badgeColor = 'red';
            if (coverage >= 90) badgeColor = 'brightgreen';
            else if (coverage >= 75) badgeColor = 'green';
            else if (coverage >= 60) badgeColor = 'yellow';
            else if (coverage >= 40) badgeColor = 'orange';

            // Determine PR badge color based on PR coverage
            const prCoverage = prJsonReport ? prJsonReport.coverage_percentage : 100;
            let prBadgeColor = 'red';
            if (prCoverage >= 90) prBadgeColor = 'brightgreen';
            else if (prCoverage >= 75) prBadgeColor = 'green';
            else if (prCoverage >= 60) prBadgeColor = 'yellow';
            else if (prCoverage >= 40) prBadgeColor = 'orange';

            // Create documentation coverage badges
            const badgeUrl = `https://img.shields.io/badge/Total%20Coverage-${Math.round(coverage)}%25-${badgeColor}?style=flat&logo=gitbook&logoColor=white`;
            const prBadgeUrl = `https://img.shields.io/badge/PR%20Coverage-${Math.round(prCoverage)}%25-${prBadgeColor}?style=flat&logo=git&logoColor=white`;

            // Create artifact download badges
            const csvBadgeUrl = `https://img.shields.io/badge/📊%20CSV%20Report-Download-blue?style=flat&logo=microsoftexcel&logoColor=white`;
            const htmlBadgeUrl = `https://img.shields.io/badge/📋%20HTML%20Report-Download-green?style=flat&logo=html5&logoColor=white`;

            // Create artifact download URLs
            const runId = context.runId;
            const repoUrl = `https://github.com/${context.repo.owner}/${context.repo.repo}`;
            const artifactUrl = `${repoUrl}/actions/runs/${runId}`;

            // Format the comment
            const prNumber = context.issue.number;
            const documentedFiles = jsonReport ? jsonReport.documented_files : 0;
            const totalFiles = jsonReport ? jsonReport.total_code_files : 0;
            const prDocumentedFiles = prJsonReport ? prJsonReport.documented_files : 0;
            const prTotalFiles = prJsonReport ? prJsonReport.total_code_files : 0;
            const prChangedFiles = prJsonReport ? prJsonReport.pr_files.length : 0;

            // Generate PR-specific details if available
            let prDetailsSection = '';
            if (prJsonReport && prJsonReport.pr_files && prJsonReport.pr_files.length > 0) {
              const prFiles = prJsonReport.pr_files;
              const prGaps = prJsonReport.gaps || [];
              const missingDocs = prGaps.filter(gap => gap.gap_type === 'missing');
              const inadequateDocs = prGaps.filter(gap => gap.gap_type === 'inadequate');
              
              prDetailsSection = `<details>\n<summary>🔍 PR-Specific Analysis (${prFiles.length} files changed)</summary>\n\n`;
              
              if (prFiles.length > 0) {
                prDetailsSection += `**Files Changed in this PR:**\n`;
                prFiles.slice(0, 10).forEach(file => {
                  prDetailsSection += `- \`${file}\`\n`;
                });
                if (prFiles.length > 10) {
                  prDetailsSection += `- ... and ${prFiles.length - 10} more files\n`;
                }
                prDetailsSection += `\n`;
              }
              
              if (missingDocs.length > 0) {
                prDetailsSection += `**Missing Documentation (${missingDocs.length} files):**\n`;
                missingDocs.slice(0, 5).forEach(gap => {
                  prDetailsSection += `- \`${gap.code_file}\` (${gap.priority} priority)\n`;
                });
                if (missingDocs.length > 5) {
                  prDetailsSection += `- ... and ${missingDocs.length - 5} more files\n`;
                }
                prDetailsSection += `\n`;
              }
              
              if (inadequateDocs.length > 0) {
                prDetailsSection += `**Inadequate Documentation (${inadequateDocs.length} files):**\n`;
                inadequateDocs.slice(0, 5).forEach(gap => {
                  prDetailsSection += `- \`${gap.code_file}\` (${gap.priority} priority)\n`;
                });
                if (inadequateDocs.length > 5) {
                  prDetailsSection += `- ... and ${inadequateDocs.length - 5} more files\n`;
                }
                prDetailsSection += `\n`;
              }
              
              if (prGaps.length === 0) {
                prDetailsSection += `✅ **All changed files have adequate documentation!**\n\n`;
              }
              
              prDetailsSection += `</details>\n\n`;
            }

            const comment = `## 📚 Documentation Coverage Status\n\n` +
              `![Total Coverage](${badgeUrl}) ![PR Coverage](${prBadgeUrl}) | ` +
              `[![CSV Report](${csvBadgeUrl})](${artifactUrl}) | ` +
              `[![HTML Report](${htmlBadgeUrl})](${artifactUrl})\n\n` +
              `### 📊 Coverage Summary\n\n` +
              `| Metric | Coverage | Files |\n` +
              `|--------|----------|-------|\n` +
              `| **Total Project** | ${coverage.toFixed(1)}% | ${documentedFiles}/${totalFiles} |\n` +
              `| **This PR** | ${prCoverage.toFixed(1)}% | ${prDocumentedFiles}/${prTotalFiles} |\n` +
              `| **Files Changed** | - | ${prChangedFiles} source files |\n\n` +
              prDetailsSection +
              `<details>\n<summary>📥 Download Coverage Reports</summary>\n\n` +
              `#### 🌍 Total Project Coverage\n` +
              `- **📊 CSV Report**: [Download for Excel/Google Sheets](${artifactUrl}) - Perfect for analysis and tracking\n` +
              `- **📋 HTML Report**: [Download Interactive Report](${artifactUrl}) - Beautiful visual interface with filtering\n` +
              `- **📄 JSON Report**: [Download Raw Data](${artifactUrl}) - API integration and automation\n\n` +
              `#### 🔍 PR-Specific Coverage\n` +
              `- **📊 PR CSV Report**: [Download PR Analysis](${artifactUrl}) - Only files changed in this PR\n` +
              `- **📋 PR HTML Report**: [Download PR Interactive Report](${artifactUrl}) - Visual analysis of PR changes\n` +
              `- **📄 PR JSON Report**: [Download PR Raw Data](${artifactUrl}) - PR-specific structured data\n\n` +
              `*Click the badges above or visit the [workflow artifacts](${artifactUrl}) to download reports.*\n\n` +
              `</details>\n\n` +
              `<details>\n<summary>📋 Detailed Analysis Report (Total Project)</summary>\n\n${reportContent}\n\n</details>\n\n` +
              `---\n\n` +
              `*This report was automatically generated by the documentation coverage analysis.*`;

            // Post comment
            await github.rest.issues.createComment({
              issue_number: prNumber,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });

            console.log('✅ Posted documentation coverage comment with artifact links on PR');

      # Update PR description with documentation coverage badge and artifact links
      - name: Update PR description with documentation coverage badge and artifacts
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');

            // Read the JSON report for structured data
            let jsonReport = null;
            try {
              jsonReport = JSON.parse(fs.readFileSync('doc-coverage-report.json', 'utf8'));
            } catch (error) {
              console.log('Could not parse JSON report:', error);
              return;
            }

            // Determine badge color based on coverage
            const coverage = jsonReport.coverage_percentage;
            let badgeColor = 'red';
            if (coverage >= 90) badgeColor = 'brightgreen';
            else if (coverage >= 75) badgeColor = 'green';
            else if (coverage >= 60) badgeColor = 'yellow';
            else if (coverage >= 40) badgeColor = 'orange';

            // Create documentation coverage badge URL
            const newBadgeUrl = `https://img.shields.io/badge/Documentation%20Coverage-${Math.round(coverage)}%25-${badgeColor}?style=flat&logo=gitbook&logoColor=white`;

            // Create artifact download badges
            const csvBadgeUrl = `https://img.shields.io/badge/📊%20CSV-Download-blue?style=flat&logo=microsoftexcel&logoColor=white`;
            const htmlBadgeUrl = `https://img.shields.io/badge/📋%20HTML-Download-green?style=flat&logo=html5&logoColor=white`;

            // Create artifact download URLs
            const runId = context.runId;
            const repoUrl = `https://github.com/${context.repo.owner}/${context.repo.repo}`;
            const artifactUrl = `${repoUrl}/actions/runs/${runId}`;

            // Get current PR description
            const prNumber = context.issue.number;
            const { data: pr } = await github.rest.pulls.get({
              owner: context.repo.owner,
              repo: context.repo.repo,
              pull_number: prNumber
            });

            let currentDescription = pr.body || '';

            // Read the PR-specific JSON report for PR description
            let prJsonReportForDesc = null;
            try {
              prJsonReportForDesc = JSON.parse(fs.readFileSync('pr-doc-coverage-report.json', 'utf8'));
            } catch (error) {
              console.log('Could not parse PR JSON report for description:', error);
            }

            // Calculate PR coverage for description
            const prCoverageForDesc = prJsonReportForDesc ? prJsonReportForDesc.coverage_percentage : 100;
            let prBadgeColorForDesc = 'red';
            if (prCoverageForDesc >= 90) prBadgeColorForDesc = 'brightgreen';
            else if (prCoverageForDesc >= 75) prBadgeColorForDesc = 'green';
            else if (prCoverageForDesc >= 60) prBadgeColorForDesc = 'yellow';
            else if (prCoverageForDesc >= 40) prBadgeColorForDesc = 'orange';

            const prBadgeUrlForDesc = `https://img.shields.io/badge/PR%20Coverage-${Math.round(prCoverageForDesc)}%25-${prBadgeColorForDesc}?style=flat&logo=git&logoColor=white`;

            // Create new badge section with collapsible artifact links
            const newBadgeSection = `## 📚 Documentation Coverage Status\n\n` +
              `![Total Coverage](${newBadgeUrl}) ![PR Coverage](${prBadgeUrlForDesc}) | ` +
              `[![CSV Report](${csvBadgeUrl})](${artifactUrl}) | ` +
              `[![HTML Report](${htmlBadgeUrl})](${artifactUrl})\n\n` +
              `<details>\n<summary>📥 Download Coverage Reports for this PR</summary>\n\n` +
              `**Total Project Coverage:** [📊 CSV](${artifactUrl}) | [📋 HTML](${artifactUrl}) | [📄 JSON](${artifactUrl})\n\n` +
              `**PR-Specific Coverage:** [📊 CSV](${artifactUrl}) | [📋 HTML](${artifactUrl}) | [📄 JSON](${artifactUrl})\n\n` +
              `</details>\n\n` +
              `---\n\n`;

            // Update existing documentation coverage section in PR description
            const badgePatterns = [
              /## 📚 Documentation Coverage Status.*?---\n\n/gs,
              /!\[Documentation Coverage\]\(https:\/\/img\.shields\.io\/badge\/Documentation%20Coverage-\d+%25-[a-z]+\?[^)]*\).*?(?=\n##|\n---|\n\n##|$)/gs,
              /!\[Documentation Coverage\]\(https:\/\/img\.shields\.io\/badge\/Documentation%20Coverage-\d+%25-[a-z]+[^)]*\).*?(?=\n##|\n---|\n\n##|$)/gs
            ];

            let updatedDescription = currentDescription;
            let badgeFound = false;

            // Try to replace existing badge section with new one
            for (const pattern of badgePatterns) {
              if (pattern.test(updatedDescription)) {
                updatedDescription = updatedDescription.replace(pattern, newBadgeSection);
                badgeFound = true;
                console.log('✅ Found and updated existing documentation coverage section in PR description');
                break;
              }
            }

            // If no badge found, add one at the top of the description
            if (!badgeFound) {
              updatedDescription = newBadgeSection + currentDescription;
              console.log('✅ Added new documentation coverage section to PR description');
            }

            // Update PR description if it changed
            if (updatedDescription !== currentDescription) {
              await github.rest.pulls.update({
                owner: context.repo.owner,
                repo: context.repo.repo,
                pull_number: prNumber,
                body: updatedDescription
              });
              console.log('✅ Updated PR description with documentation coverage badge and artifact links');
            } else {
              console.log('📝 PR description already up to date');
            }

      # Generate OpenAPI specification before building docs
      - name: Generate OpenAPI specification
        run: pnpm docs:openapi

      - name: OpenAPI Documentation Status
        run: |
          echo "📚 Using Redocusaurus for OpenAPI documentation"
          echo "✅ OpenAPI spec generated at: src/app/api/openapi.json"
          echo "🌐 API documentation will be available at: /api/"

      # Build Docusaurus documentation site
      - name: Build Docusaurus site
        run: |
          echo "📚 Building Docusaurus documentation site..."
          pnpm docs:build
        env:
          NODE_ENV: production

      # Upload Pages artifact for deployment (only on main/master branch)
      - name: Upload Pages artifact
        if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'
        uses: actions/upload-pages-artifact@v3
        with:
          path: ./build/

      # Deploy to GitHub Pages (only on main/master branch)
      - name: Deploy to GitHub Pages
        if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'
        id: deployment
        uses: actions/deploy-pages@v4
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  jest-tests:
    timeout-minutes: 15
    name: Jest Tests
    needs: setup
    runs-on: ubuntu-latest
    environment: actions
    strategy:
      fail-fast: false
      matrix:
        shard: [1, 2, 3] # Run tests in 3 parallel shards
    steps:
      - uses: actions/checkout@v4

      # Use the same Node.js version as setup job
      - uses: actions/setup-node@v4
        with:
          node-version: lts/*

      # Enable Corepack to use packageManager from package.json
      - name: Enable Corepack
        run: |
          corepack enable
          corepack install

      # Restore cached dependencies from setup job
      - name: Restore dependencies cache
        id: cache-restore
        uses: actions/cache/restore@v4
        with:
          path: |
            node_modules
            ~/.cache/playwright
            ~/.cache/ms-playwright
          key: ${{ runner.os }}-deps-browsers-${{ hashFiles('**/pnpm-lock.yaml', '**/package.json') }}
          restore-keys: |
            ${{ runner.os }}-deps-browsers-
            ${{ runner.os }}-deps-
          fail-on-cache-miss: false

      # Install dependencies if cache miss (first run or cache eviction)
      - name: Install dependencies
        if: steps.cache-restore.outputs.cache-hit != 'true'
        run: pnpm install

      # Run unit tests with sharding
      - name: Run Jest tests (Shard ${{ matrix.shard }}/3)
        run: |
          echo "::group::Running Jest Tests (Shard ${{ matrix.shard }}/3)"
          FORCE_COLOR=1 pnpm test:coverage --ci --colors --json --shard=${{ matrix.shard }}/3 --testLocationInResults --outputFile="$GITHUB_WORKSPACE/jest-results-${{ matrix.shard }}.json"
          echo "::endgroup::"

      # Upload coverage reports for each shard
      - name: Upload Jest coverage
        if: ${{ !cancelled() }}
        uses: actions/upload-artifact@v4
        with:
          name: jest-coverage-${{ matrix.shard }}
          path: coverage/
          retention-days: 30

  # SonarCloud analysis job (matches original working setup)
  sonar:
    timeout-minutes: 15
    name: SonarCloud Analysis
    needs: [playwright-tests, jest-tests, documentation-coverage]
    if: ${{ !cancelled() }} # Run even if some tests fail
    runs-on: ubuntu-latest
    environment: actions
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      # Download Jest coverage artifacts
      - name: Download Jest coverage artifacts
        continue-on-error: true
        uses: actions/download-artifact@v4
        with:
          pattern: jest-coverage-*
          merge-multiple: true

      # Download documentation coverage artifacts
      - name: Download documentation coverage artifacts
        continue-on-error: true
        uses: actions/download-artifact@v4
        with:
          name: documentation-coverage-reports
          path: coverage/

      # Install xmllint for XML validation
      - name: Install XML tools
        run: sudo apt-get update && sudo apt-get install -y libxml2-utils

      # Ensure coverage directory exists and validate XML files
      - name: Prepare coverage directory and validate XML
        run: |
          echo "📁 Creating coverage directory if it doesn't exist..."
          mkdir -p coverage

          echo "📊 Coverage directory contents:"
          ls -la coverage/ || echo "No coverage directory found"

          echo "📁 All XML files in workspace:"
          find . -name "*.xml" -type f | head -20

          # Check if documentation XML exists and validate it
          if [ -f "coverage/documentation-test-execution.xml" ]; then
            echo "✅ Found documentation-test-execution.xml"
            echo "📋 XML content preview:"
            head -10 coverage/documentation-test-execution.xml
            
            # Validate XML syntax if xmllint is available
            if command -v xmllint >/dev/null 2>&1; then
              echo "🔍 Validating XML syntax..."
              if xmllint --noout coverage/documentation-test-execution.xml; then
                echo "✅ XML is valid"
              else
                echo "❌ XML is invalid - creating fallback"
                # Create a minimal valid XML file as fallback
                {
                  printf '<?xml version="1.0" encoding="UTF-8"?>\n'
                  printf '<testExecutions version="1">\n'
                  printf '  <file path="tests/documentation-coverage.test.js">\n'
                  printf '    <testCase name="Documentation Coverage Test" duration="100">\n'
                  printf '      <failure message="XML generation failed">Documentation coverage XML could not be generated properly</failure>\n'
                  printf '    </testCase>\n'
                  printf '  </file>\n'
                  printf '</testExecutions>\n'
                } > coverage/documentation-test-execution.xml
              fi
            fi
          else
            echo "❌ documentation-test-execution.xml not found - creating fallback"
            # Create a minimal valid XML file as fallback
            {
              printf '<?xml version="1.0" encoding="UTF-8"?>\n'
              printf '<testExecutions version="1">\n'
              printf '  <file path="tests/documentation-coverage.test.js">\n'
              printf '    <testCase name="Documentation Coverage Test" duration="100">\n'
              printf '      <failure message="XML file missing">Documentation coverage XML file was not generated or uploaded</failure>\n'
              printf '    </testCase>\n'
              printf '  </file>\n'
              printf '</testExecutions>\n'
            } > coverage/documentation-test-execution.xml
            echo "📋 Created fallback XML file"
          fi

      # Clear any existing SonarCloud cache and force fresh download
      - name: Clear SonarCloud cache and force fresh scanner
        run: |
          echo "🧹 Clearing SonarCloud cache..."
          rm -rf ~/.sonar/cache || true
          rm -rf /tmp/sonar-scanner-* || true
          rm -rf /home/runner/.sonar || true
          echo "✅ Cache cleared"

          # Force a different cache key by creating a timestamp file
          echo "CACHE_BUSTER=$(date +%s)" >> $GITHUB_ENV

      # Run SonarCloud analysis with cache busting
      - name: SonarCloud Scan
        continue-on-error: true
        uses: SonarSource/sonarqube-scan-action@v5.0.0
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
          # Force fresh analysis with cache busting
          SONAR_SCANNER_OPTS: '-Dsonar.scanner.cacheEnabled=false -Dsonar.cache.dir=/tmp/sonar-cache-${{ env.CACHE_BUSTER }}'

      # Add SonarCloud badges to PR description
      - name: 📊 Update PR with SonarCloud badges
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const projectKey = 'Underwood-Inc_idling.app__UI';
            const prNumber = context.issue.number;

            // Generate SonarCloud badge URLs for this specific PR
            const qualityGateBadge = `https://sonarcloud.io/api/project_badges/measure?project=${projectKey}&metric=alert_status&pullRequest=${prNumber}`;
            const bugsBadge = `https://sonarcloud.io/api/project_badges/measure?project=${projectKey}&metric=bugs&pullRequest=${prNumber}`;
            const codeSmellsBadge = `https://sonarcloud.io/api/project_badges/measure?project=${projectKey}&metric=code_smells&pullRequest=${prNumber}`;
            const coverageBadge = `https://sonarcloud.io/api/project_badges/measure?project=${projectKey}&metric=coverage&pullRequest=${prNumber}`;
            const duplicatedLinesBadge = `https://sonarcloud.io/api/project_badges/measure?project=${projectKey}&metric=duplicated_lines_density&pullRequest=${prNumber}`;
            const linesOfCodeBadge = `https://sonarcloud.io/api/project_badges/measure?project=${projectKey}&metric=ncloc&pullRequest=${prNumber}`;
            const reliabilityBadge = `https://sonarcloud.io/api/project_badges/measure?project=${projectKey}&metric=reliability_rating&pullRequest=${prNumber}`;
            const securityBadge = `https://sonarcloud.io/api/project_badges/measure?project=${projectKey}&metric=security_rating&pullRequest=${prNumber}`;
            const maintainabilityBadge = `https://sonarcloud.io/api/project_badges/measure?project=${projectKey}&metric=sqale_rating&pullRequest=${prNumber}`;

            const sonarCloudUrl = `https://sonarcloud.io/summary/new_code?id=${projectKey}&pullRequest=${prNumber}`;

            // Create SonarCloud badges section
            const sonarBadgesSection = `## 🔍 SonarCloud Analysis\n\n` +
              `[![Quality Gate Status](${qualityGateBadge})](${sonarCloudUrl})\n` +
              `[![Bugs](${bugsBadge})](${sonarCloudUrl})\n` +
              `[![Code Smells](${codeSmellsBadge})](${sonarCloudUrl})\n` +
              `[![Coverage](${coverageBadge})](${sonarCloudUrl})\n` +
              `[![Duplicated Lines (%)](${duplicatedLinesBadge})](${sonarCloudUrl})\n` +
              `[![Lines of Code](${linesOfCodeBadge})](${sonarCloudUrl})\n` +
              `[![Reliability Rating](${reliabilityBadge})](${sonarCloudUrl})\n` +
              `[![Security Rating](${securityBadge})](${sonarCloudUrl})\n` +
              `[![Maintainability Rating](${maintainabilityBadge})](${sonarCloudUrl})\n\n` +
              `[📊 View Detailed Analysis on SonarCloud](${sonarCloudUrl})\n\n` +
              `---\n\n`;

            // Get current PR description
            const { data: pr } = await github.rest.pulls.get({
              owner: context.repo.owner,
              repo: context.repo.repo,
              pull_number: prNumber
            });

            let currentDescription = pr.body || '';

            // Remove existing SonarCloud section if present
            currentDescription = currentDescription.replace(
              /## 🔍 SonarCloud Analysis.*?---\n\n/s,
              ''
            );

            // Add SonarCloud section at the top (after documentation coverage if present)
            let newDescription;
            if (currentDescription.includes('## 📚 Documentation Coverage Status')) {
              // Insert after documentation coverage section
              newDescription = currentDescription.replace(
                /(## 📚 Documentation Coverage Status.*?---\n\n)/s,
                `$1${sonarBadgesSection}`
              );
            } else {
              // Add at the very top
              newDescription = sonarBadgesSection + currentDescription.trim();
            }

            // Update PR description
            await github.rest.pulls.update({
              owner: context.repo.owner,
              repo: context.repo.repo,
              pull_number: prNumber,
              body: newDescription
            });

            console.log('✅ Updated PR description with SonarCloud badges');

  # Status reporting jobs that consolidate matrix results
  playwright-status:
    name: Playwright Status
    needs: playwright-tests
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Report Playwright Status
        uses: actions/github-script@v7
        with:
          script: |
            const jobs = ${{ toJson(needs.playwright-tests.result) }};
            const success = jobs === 'success';
            const skipped = jobs === 'skipped';

            console.log(`Playwright tests result: ${jobs}`);

            if (skipped) {
              console.log('✅ Playwright tests were skipped');
            } else if (success) {
              console.log('✅ All Playwright tests passed');
            } else {
              console.log('❌ Some Playwright tests failed (non-blocking)');
            }

  jest-status:
    name: Jest Status
    needs: jest-tests
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Report Jest Status
        uses: actions/github-script@v7
        with:
          script: |
            const jobs = ${{ toJson(needs.jest-tests.result) }};
            const success = jobs === 'success';

            console.log(`Jest tests result: ${jobs}`);

            if (success) {
              console.log('✅ All Jest tests passed');
            } else {
              console.log('❌ Jest tests failed');
              process.exit(1);
            }

  documentation-status:
    name: Documentation Status
    needs: documentation-coverage
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Report Documentation Status
        uses: actions/github-script@v7
        with:
          script: |
            const jobs = ${{ toJson(needs.documentation-coverage.result) }};
            const success = jobs === 'success';

            console.log(`Documentation coverage result: ${jobs}`);

            if (success) {
              console.log('✅ Documentation coverage analysis completed');
            } else {
              console.log('❌ Documentation coverage analysis failed (non-blocking)');
            }

  # Final status job
  tests-complete:
    name: Quality Assurance Complete
    needs: [jest-status, playwright-status, documentation-status, sonar]
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Report Final Status
        run: |
          echo "🧪 Quality Assurance Complete"
          echo "============================"
          echo "Jest: ${{ needs.jest-status.result }}"
          echo "Playwright: ${{ needs.playwright-status.result }}"
          echo "Documentation: ${{ needs.documentation-status.result }}"
          echo "SonarCloud: ${{ needs.sonar.result }}"

          if [[ "${{ needs.jest-status.result }}" == "success" ]]; then
            echo "✅ All required tests passed"
            if [[ "${{ needs.documentation-status.result }}" == "success" ]]; then
              echo "✅ Documentation coverage analysis completed"
            else
              echo "⚠️ Documentation coverage needs attention (non-blocking)"
            fi
            if [[ "${{ needs.sonar.result }}" == "success" ]]; then
              echo "✅ SonarCloud analysis completed successfully"
            else
              echo "⚠️ SonarCloud analysis had issues (non-blocking)"
            fi
          else
            echo "❌ Required tests failed"
            exit 1
          fi
